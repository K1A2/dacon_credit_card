{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1637462488630,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "7g3RNx0aLKI1"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "from itertools import product\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpivcwglXXiI"
   },
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1637462755021,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "Fa0haHggVoiV",
    "outputId": "910c72b8-7f58-4683-cae3-1fda8b5d761b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gender</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>income_type</th>\n",
       "      <th>Education</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>working_day</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>car_reality</th>\n",
       "      <th>credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>-13899</td>\n",
       "      <td>-4709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-11380</td>\n",
       "      <td>-1540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19087</td>\n",
       "      <td>-4434</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-15088</td>\n",
       "      <td>-2092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-15037</td>\n",
       "      <td>-2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26452</th>\n",
       "      <td>26452</td>\n",
       "      <td>F</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-12079</td>\n",
       "      <td>-1984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>26453</td>\n",
       "      <td>F</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Separated</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-15291</td>\n",
       "      <td>-2475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26454</th>\n",
       "      <td>26454</td>\n",
       "      <td>F</td>\n",
       "      <td>292500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>With parents</td>\n",
       "      <td>-10082</td>\n",
       "      <td>-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26455</th>\n",
       "      <td>26455</td>\n",
       "      <td>M</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Incomplete higher</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-10145</td>\n",
       "      <td>-107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26456</th>\n",
       "      <td>26456</td>\n",
       "      <td>F</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19569</td>\n",
       "      <td>-1013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26457 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index gender  Annual_income           income_type  \\\n",
       "0          0      F       202500.0  Commercial associate   \n",
       "1          1      F       247500.0  Commercial associate   \n",
       "2          2      M       450000.0               Working   \n",
       "3          3      F       202500.0  Commercial associate   \n",
       "4          4      F       157500.0         State servant   \n",
       "...      ...    ...            ...                   ...   \n",
       "26452  26452      F       225000.0         State servant   \n",
       "26453  26453      F       180000.0               Working   \n",
       "26454  26454      F       292500.0               Working   \n",
       "26455  26455      M       171000.0               Working   \n",
       "26456  26456      F        81000.0               Working   \n",
       "\n",
       "                           Education           family_type  \\\n",
       "0                   Higher education               Married   \n",
       "1      Secondary / secondary special        Civil marriage   \n",
       "2                   Higher education               Married   \n",
       "3      Secondary / secondary special               Married   \n",
       "4                   Higher education               Married   \n",
       "...                              ...                   ...   \n",
       "26452  Secondary / secondary special               Married   \n",
       "26453               Higher education             Separated   \n",
       "26454  Secondary / secondary special        Civil marriage   \n",
       "26455              Incomplete higher  Single / not married   \n",
       "26456  Secondary / secondary special        Civil marriage   \n",
       "\n",
       "                house_type  DAYS_BIRTH  working_day  FLAG_MOBIL  work_phone  \\\n",
       "0      Municipal apartment      -13899        -4709           1           0   \n",
       "1        House / apartment      -11380        -1540           1           0   \n",
       "2        House / apartment      -19087        -4434           1           0   \n",
       "3        House / apartment      -15088        -2092           1           0   \n",
       "4        House / apartment      -15037        -2105           1           0   \n",
       "...                    ...         ...          ...         ...         ...   \n",
       "26452    House / apartment      -12079        -1984           1           0   \n",
       "26453    House / apartment      -15291        -2475           1           0   \n",
       "26454         With parents      -10082        -2015           1           0   \n",
       "26455    House / apartment      -10145         -107           1           0   \n",
       "26456    House / apartment      -19569        -1013           1           0   \n",
       "\n",
       "       phone  email      occyp_type  begin_month  car_reality  credit  \n",
       "0          0      0             NaN         -6.0            0     1.0  \n",
       "1          0      1        Laborers         -5.0            1     1.0  \n",
       "2          1      0        Managers        -22.0            2     2.0  \n",
       "3          1      0     Sales staff        -37.0            1     0.0  \n",
       "4          0      0        Managers        -26.0            2     2.0  \n",
       "...      ...    ...             ...          ...          ...     ...  \n",
       "26452      0      0      Core staff         -2.0            0     1.0  \n",
       "26453      0      0             NaN        -47.0            1     2.0  \n",
       "26454      0      0      Core staff        -25.0            1     2.0  \n",
       "26455      0      0        Laborers        -59.0            1     2.0  \n",
       "26456      0      0  Security staff         -9.0            0     2.0  \n",
       "\n",
       "[26457 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('./data/train.csv')\n",
    "test_csv = pd.read_csv('./data/test.csv')\n",
    "sample_submission_csv = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "train_data = train_csv.copy()\n",
    "test_data = test_csv.copy()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1637462756890,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "lTkzGxK9Whwj"
   },
   "outputs": [],
   "source": [
    "numermic_col = ['Annual_income','working_day','begin_month','DAYS_BIRTH']\n",
    "default_cate_col = ['gender','income_type','Education','family_type','house_type','work_phone','phone','email','occyp_type','car_reality']\n",
    "cate_col = ['gender','income_type','Education','family_type','house_type','work_phone','phone','email','occyp_type','car_reality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7HxyEN4Xw3t"
   },
   "source": [
    "## 데이터 전처리\n",
    "### 필요 없는 변수 제거\n",
    "모두 1인 **FLAG_MOBIL** 제거.  \n",
    "데이터 순서를 나타내는 **index** 제거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1637462765815,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "zDSKoTv9XUYQ"
   },
   "outputs": [],
   "source": [
    "# index와 FLAG_MOBIL drop\n",
    "train_data.drop(['index','FLAG_MOBIL'],inplace=True,axis=1)\n",
    "test_data.drop(['index','FLAG_MOBIL'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxitU6l3XfDo"
   },
   "source": [
    "### 결측치 채워넣기\n",
    "직업 종류를 나타내는 **occyp_type**만 결측치가 있는것으로 확인 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1637462759969,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "t58eud8fXlYJ",
    "outputId": "cde6889f-1584-426f-9ef6-5869a69636bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender           0.000000\n",
       "Annual_income    0.000000\n",
       "income_type      0.000000\n",
       "Education        0.000000\n",
       "family_type      0.000000\n",
       "house_type       0.000000\n",
       "DAYS_BIRTH       0.000000\n",
       "working_day      0.000000\n",
       "work_phone       0.000000\n",
       "phone            0.000000\n",
       "email            0.000000\n",
       "occyp_type       0.308841\n",
       "begin_month      0.000000\n",
       "car_reality      0.000000\n",
       "credit           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "train_data.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fillna로 직업이 없는 칸에 **None**으로 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1637462762083,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "jzjJ4ajAXNuF"
   },
   "outputs": [],
   "source": [
    "# null을 모두 None으로 변경\n",
    "train_data.fillna(\"None\",inplace=True)\n",
    "test_data.fillna(\"None\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORvq56MfaJxW"
   },
   "source": [
    "working_day가 0이고 occuyp_type이 None이면 **무직자**라고 판단.  \n",
    "working_day가 0이 아니고 ocuuup_type이 None이면 **결측치**라고 판단."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1637462906235,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "_aW8GADdXU2i"
   },
   "outputs": [],
   "source": [
    "# working_day == 0 && occyp_type == None은 무직자\n",
    "train_data.loc[((train_data['working_day']== 0) & (train_data['occyp_type'] == \"None\")),'occyp_type'] = 'No_Job'\n",
    "test_data.loc[((test_data['working_day']== 0) & (test_data['occyp_type'] == \"None\")),'occyp_type'] = 'No_Job'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivziHU9Icx2b"
   },
   "source": [
    "### Numerical 데이터 전처리\n",
    "최대한 여러 종류의 데이터를 만들려고 시도. \n",
    "  \n",
    "음수를 모두 양수로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1637462938193,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "nsZZaCYXYFyr"
   },
   "outputs": [],
   "source": [
    "# DAYS_BIRTH 모두 양수로 변환\n",
    "train_data['DAYS_BIRTH'] = np.abs(train_data['DAYS_BIRTH'])\n",
    "test_data['DAYS_BIRTH'] = np.abs(test_data['DAYS_BIRTH'])\n",
    "\n",
    "# working_day 모두 양수로 변환\n",
    "train_data['working_day'] = np.abs(train_data['working_day'])\n",
    "test_data['working_day'] = np.abs(test_data['working_day'])\n",
    "\n",
    "# begin_month 모두 양수로 변환\n",
    "train_data['begin_month'] = np.abs(train_data['begin_month'])\n",
    "test_data['begin_month'] = np.abs(test_data['begin_month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBEmJqTldycR"
   },
   "source": [
    "무직자로 지낸 기간 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1637464204481,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "M22gB4NzZYyz"
   },
   "outputs": [],
   "source": [
    "df = train_data\n",
    "\n",
    "# 무직자로 지낸 기간 not_working_day로 추가\n",
    "df['not_working_day'] = df['DAYS_BIRTH'] - df['working_day']\n",
    "numermic_col.append('not_working_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62hrNegQeVgE"
   },
   "source": [
    "나이 데이터 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1637464231029,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "p5DYyRTCeOBl"
   },
   "outputs": [],
   "source": [
    "# 산 나이 (년, 월, 주) 각각 age_y, age_m, age_w 추가\n",
    "df['age_y'] = df['DAYS_BIRTH'] // 365\n",
    "numermic_col.append('age_y')\n",
    "df['age_m'] = df['DAYS_BIRTH'] % 365 // 30\n",
    "numermic_col.append('age_m')\n",
    "df['age_w'] = df['DAYS_BIRTH'] % 365 % 30 // 7\n",
    "numermic_col.append('age_w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yg0Y--IzekAM"
   },
   "source": [
    "일한 기간 연, 월, 주 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1637464289313,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "CJIVqzWCeUiu"
   },
   "outputs": [],
   "source": [
    "# 일한 기간 (년, 월, 주) 각각 working_y, working_m, working_w 추가\n",
    "df['working_y'] = df['working_day'] // 365\n",
    "numermic_col.append('working_y')\n",
    "df['working_m'] = df['working_day'] % 365 // 30\n",
    "numermic_col.append('working_m')\n",
    "df['working_w'] = df['working_day'] % 365 % 30 // 7\n",
    "numermic_col.append('working_w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNO_FlrVe16h"
   },
   "source": [
    "카드를 만든 기간 연, 월 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1637464364548,
     "user": {
      "displayName": "K1 A2",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjvlpcupqq2k-HUpMZRhgsB-I0pdbidsL1YrEGCgA=s64",
      "userId": "14415427705313692075"
     },
     "user_tz": -540
    },
    "id": "KhVddyHxeiu8"
   },
   "outputs": [],
   "source": [
    "# 카드를 만들고 경과한 시간 (년, 월) 각각 begin_y, begin_m 추가\n",
    "df['begin_y'] = df['begin_month'] // 12\n",
    "numermic_col.append('begin_y')\n",
    "df['begin_m'] = df['begin_month'] % 12\n",
    "numermic_col.append('begin_m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지 전처리."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XMeZWPIOe1Gy"
   },
   "outputs": [],
   "source": [
    "df['begin_prop_income'] = np.floor(df['Annual_income']  / df['begin_month'])\n",
    "numermic_col.append('begin_prop_income')\n",
    "\n",
    "# inf 데이터 모두 0으로 치환\n",
    "df.replace(-np.inf,0,inplace=True)\n",
    "df.replace(np.inf,0,inplace=True)\n",
    "\n",
    "# 혹시 모를 결측치 모두 0으로 설정\n",
    "df.fillna(0,inplace=True)\n",
    "train_data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 데이터도 똑같이 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_data\n",
    "df['not_working_day'] = df['DAYS_BIRTH'] - df['working_day']\n",
    "df['age_y'] = df['DAYS_BIRTH'] // 365\n",
    "df['age_m'] = df['DAYS_BIRTH'] % 365 // 30\n",
    "df['age_w'] = df['DAYS_BIRTH'] % 365 % 30 // 7\n",
    "\n",
    "df['working_y'] = df['working_day'] // 365\n",
    "df['working_m'] = df['working_day'] % 365 // 30\n",
    "df['working_w'] = df['working_day'] % 365 % 30 // 7\n",
    "\n",
    "df['begin_y'] = df['begin_month'] // 12\n",
    "df['begin_m'] = df['begin_month'] % 12\n",
    "df['begin_prop_income'] = np.floor(df['Annual_income']  / df['begin_month'])\n",
    "\n",
    "df.replace(-np.inf,0,inplace=True)\n",
    "df.replace(np.inf,0,inplace=True)\n",
    "df.fillna(0,inplace=True)\n",
    "test_data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터에서 클래스 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스만 train_data_y로 분리\n",
    "train_data_y = train_data['credit'].astype(int)\n",
    "# train_data에서 클래스와 index drop\n",
    "train_data.drop('credit',axis=1,inplace=True)\n",
    "train_data.reset_index(inplace=True)\n",
    "train_data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical 데이터 LabelEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in default_cate_col:\n",
    "    encoder = LabelEncoder()\n",
    "    train_data[col] = encoder.fit_transform(train_data[col])\n",
    "    test_data[col] = encoder.transform(test_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>income_type</th>\n",
       "      <th>Education</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>working_day</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>car_reality</th>\n",
       "      <th>not_working_day</th>\n",
       "      <th>age_y</th>\n",
       "      <th>age_m</th>\n",
       "      <th>age_w</th>\n",
       "      <th>working_y</th>\n",
       "      <th>working_m</th>\n",
       "      <th>working_w</th>\n",
       "      <th>begin_y</th>\n",
       "      <th>begin_m</th>\n",
       "      <th>begin_prop_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13899</td>\n",
       "      <td>4709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9190</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11380</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9840</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19087</td>\n",
       "      <td>4434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14653</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15088</td>\n",
       "      <td>2092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12996</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15037</td>\n",
       "      <td>2105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12932</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26452</th>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12079</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10095</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15291</td>\n",
       "      <td>2475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12816</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26454</th>\n",
       "      <td>0</td>\n",
       "      <td>292500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10082</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8067</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26455</th>\n",
       "      <td>1</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10145</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10038</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26456</th>\n",
       "      <td>0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19569</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18556</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26457 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  Annual_income  income_type  Education  family_type  house_type  \\\n",
       "0           0       202500.0            0          1            1           2   \n",
       "1           0       247500.0            0          4            0           1   \n",
       "2           1       450000.0            4          1            1           1   \n",
       "3           0       202500.0            0          4            1           1   \n",
       "4           0       157500.0            2          1            1           1   \n",
       "...       ...            ...          ...        ...          ...         ...   \n",
       "26452       0       225000.0            2          4            1           1   \n",
       "26453       0       180000.0            4          1            2           1   \n",
       "26454       0       292500.0            4          4            0           5   \n",
       "26455       1       171000.0            4          2            3           1   \n",
       "26456       0        81000.0            4          4            0           1   \n",
       "\n",
       "       DAYS_BIRTH  working_day  work_phone  phone  email  occyp_type  \\\n",
       "0           13899         4709           0      0      0          13   \n",
       "1           11380         1540           0      0      1           8   \n",
       "2           19087         4434           0      1      0          10   \n",
       "3           15088         2092           0      1      0          16   \n",
       "4           15037         2105           0      0      0          10   \n",
       "...           ...          ...         ...    ...    ...         ...   \n",
       "26452       12079         1984           0      0      0           3   \n",
       "26453       15291         2475           0      0      0          13   \n",
       "26454       10082         2015           0      0      0           3   \n",
       "26455       10145          107           0      0      0           8   \n",
       "26456       19569         1013           0      0      0          18   \n",
       "\n",
       "       begin_month  car_reality  not_working_day  age_y  age_m  age_w  \\\n",
       "0              6.0            0             9190     38      0      4   \n",
       "1              5.0            1             9840     31      2      0   \n",
       "2             22.0            2            14653     52      3      2   \n",
       "3             37.0            1            12996     41      4      0   \n",
       "4             26.0            2            12932     41      2      1   \n",
       "...            ...          ...              ...    ...    ...    ...   \n",
       "26452          2.0            0            10095     33      1      0   \n",
       "26453         47.0            1            12816     41     10      3   \n",
       "26454         25.0            1             8067     27      7      2   \n",
       "26455         59.0            1            10038     27      9      2   \n",
       "26456          9.0            0            18556     53      7      2   \n",
       "\n",
       "       working_y  working_m  working_w  begin_y  begin_m  begin_prop_income  \n",
       "0             12         10          4      0.0      6.0            33750.0  \n",
       "1              4          2          2      0.0      5.0            49500.0  \n",
       "2             12          1          3      1.0     10.0            20454.0  \n",
       "3              5          8          3      3.0      1.0             5472.0  \n",
       "4              5          9          1      2.0      2.0             6057.0  \n",
       "...          ...        ...        ...      ...      ...                ...  \n",
       "26452          5          5          1      0.0      2.0           112500.0  \n",
       "26453          6          9          2      3.0     11.0             3829.0  \n",
       "26454          5          6          1      2.0      1.0            11700.0  \n",
       "26455          0          3          2      4.0     11.0             2898.0  \n",
       "26456          2          9          1      0.0      9.0             9000.0  \n",
       "\n",
       "[26457 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner 변수 추가\n",
    "동일한 인물로 추정되는 데이터가 여러개 있는것을 확인.\n",
    "동일 인물을 구분하기 위한 **Owner** 변수 추가.  \n",
    "gender, Annual_income, income_type, Education, family_type, house_type, DAYS_BIRTH, working_day, work_phone, phone, email, occyp_type, car_reality를 하나로 합쳐 변수 구성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Owner'] = ''\n",
    "test_data['Owner'] = ''\n",
    "for col in ['gender','Annual_income','income_type','Education','family_type','house_type','DAYS_BIRTH','working_day','work_phone','phone','email','occyp_type','car_reality']:\n",
    "    train_data['Owner'] = train_data['Owner']+ train_data[col].astype(int).astype(str)\n",
    "    test_data['Owner'] = test_data['Owner'] + test_data[col].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier, RandomForestClassifier, LGBMClassifier 학습을 위한 numerical 데이터를 categorical 데이터로 변환.  \n",
    "categorical 데이터로 변환한 변수들로 **Owner_r** 변수 추가. 그냥 Owner 변수를 LabelEncoding 하기에는 경우의 수가 너무 많아져서 이런 방식을 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual_income 범위로 자르기\n",
    "income_range = [0, 180000, 330000, 490000, 640000, \n",
    "800000, 950000, 1110000, 1260000, 1420000]\n",
    "cnt = 0\n",
    "for i in income_range:\n",
    "    train_data.loc[train_data['Annual_income'] >= i, 'Annual_income_r'] = cnt\n",
    "    test_data.loc[test_data['Annual_income'] >= i, 'Annual_income_r'] = cnt\n",
    "    cnt += 1\n",
    "# DAYS_BIRTH 범위로 자르기\n",
    "birth_range = [0, 20 * 365, 30 * 365, 40 * 365, 50 * 365, 60 * 365]\n",
    "cnt = 0\n",
    "for i in birth_range:\n",
    "    train_data.loc[train_data['DAYS_BIRTH'] >= i, 'DAYS_BIRTH_r'] = cnt\n",
    "    test_data.loc[test_data['DAYS_BIRTH'] >= i, 'DAYS_BIRTH_r'] = cnt\n",
    "    cnt += 1\n",
    "# working_day 범위로 자르기\n",
    "work_range = [0, 1 * 365, 3 * 365, 5 * 365, 7 * 365, 10 * 365]\n",
    "cnt = 0\n",
    "for i in work_range:\n",
    "    train_data.loc[train_data['working_day'] >= i, 'working_day_r'] = cnt\n",
    "    test_data.loc[test_data['working_day'] >= i, 'working_day_r'] = cnt\n",
    "    cnt += 1\n",
    "\n",
    "# 모두 categorical data 로만 구성된 Owner_r 변수\n",
    "train_data['Owner_r'] = ''\n",
    "test_data['Owner_r'] = ''\n",
    "all_l = []\n",
    "l = ['gender','income_type','Education','family_type','house_type',\n",
    "'work_phone','phone','email','occyp_type','car_reality']\n",
    "for col in l:\n",
    "    train_data['Owner_r'] = train_data['Owner_r']+ train_data[col].astype(int).astype(str)\n",
    "    test_data['Owner_r'] = test_data['Owner_r'] + test_data[col].astype(int).astype(str)\n",
    "    all_l.append([i for i in range(len(train_data[col].unique().tolist()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Owner, Owner_r 모두 str로 변환\n",
    "train_data['Owner'] = train_data['Owner'].astype(str)\n",
    "test_data['Owner'] = test_data['Owner'].astype(str)\n",
    "train_data['Owner_r'] = train_data['Owner_r'].astype(str)\n",
    "test_data['Owner_r'] = test_data['Owner_r'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>income_type</th>\n",
       "      <th>Education</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>working_day</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>car_reality</th>\n",
       "      <th>not_working_day</th>\n",
       "      <th>age_y</th>\n",
       "      <th>age_m</th>\n",
       "      <th>age_w</th>\n",
       "      <th>working_y</th>\n",
       "      <th>working_m</th>\n",
       "      <th>working_w</th>\n",
       "      <th>begin_y</th>\n",
       "      <th>begin_m</th>\n",
       "      <th>begin_prop_income</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Annual_income_r</th>\n",
       "      <th>DAYS_BIRTH_r</th>\n",
       "      <th>working_day_r</th>\n",
       "      <th>Owner_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13899</td>\n",
       "      <td>4709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9190</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33750.0</td>\n",
       "      <td>02025000112138994709000130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>00112000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11380</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9840</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>0247500040111380154000181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0040100181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19087</td>\n",
       "      <td>4434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14653</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20454.0</td>\n",
       "      <td>14500004111190874434010102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14111010102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15088</td>\n",
       "      <td>2092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12996</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5472.0</td>\n",
       "      <td>02025000411150882092010161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>00411010161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15037</td>\n",
       "      <td>2105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12932</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6057.0</td>\n",
       "      <td>01575002111150372105000102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>02111000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26452</th>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12079</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10095</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>0225000241112079198400030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0241100030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15291</td>\n",
       "      <td>2475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12816</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>01800004121152912475000131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>04121000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26454</th>\n",
       "      <td>0</td>\n",
       "      <td>292500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10082</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8067</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>0292500440510082201500031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0440500031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26455</th>\n",
       "      <td>1</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10145</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10038</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>117100042311014510700081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1423100081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26456</th>\n",
       "      <td>0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19569</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18556</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0810004401195691013000180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>04401000180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26457 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  Annual_income  income_type  Education  family_type  house_type  \\\n",
       "0           0       202500.0            0          1            1           2   \n",
       "1           0       247500.0            0          4            0           1   \n",
       "2           1       450000.0            4          1            1           1   \n",
       "3           0       202500.0            0          4            1           1   \n",
       "4           0       157500.0            2          1            1           1   \n",
       "...       ...            ...          ...        ...          ...         ...   \n",
       "26452       0       225000.0            2          4            1           1   \n",
       "26453       0       180000.0            4          1            2           1   \n",
       "26454       0       292500.0            4          4            0           5   \n",
       "26455       1       171000.0            4          2            3           1   \n",
       "26456       0        81000.0            4          4            0           1   \n",
       "\n",
       "       DAYS_BIRTH  working_day  work_phone  phone  email  occyp_type  \\\n",
       "0           13899         4709           0      0      0          13   \n",
       "1           11380         1540           0      0      1           8   \n",
       "2           19087         4434           0      1      0          10   \n",
       "3           15088         2092           0      1      0          16   \n",
       "4           15037         2105           0      0      0          10   \n",
       "...           ...          ...         ...    ...    ...         ...   \n",
       "26452       12079         1984           0      0      0           3   \n",
       "26453       15291         2475           0      0      0          13   \n",
       "26454       10082         2015           0      0      0           3   \n",
       "26455       10145          107           0      0      0           8   \n",
       "26456       19569         1013           0      0      0          18   \n",
       "\n",
       "       begin_month  car_reality  not_working_day  age_y  age_m  age_w  \\\n",
       "0              6.0            0             9190     38      0      4   \n",
       "1              5.0            1             9840     31      2      0   \n",
       "2             22.0            2            14653     52      3      2   \n",
       "3             37.0            1            12996     41      4      0   \n",
       "4             26.0            2            12932     41      2      1   \n",
       "...            ...          ...              ...    ...    ...    ...   \n",
       "26452          2.0            0            10095     33      1      0   \n",
       "26453         47.0            1            12816     41     10      3   \n",
       "26454         25.0            1             8067     27      7      2   \n",
       "26455         59.0            1            10038     27      9      2   \n",
       "26456          9.0            0            18556     53      7      2   \n",
       "\n",
       "       working_y  working_m  working_w  begin_y  begin_m  begin_prop_income  \\\n",
       "0             12         10          4      0.0      6.0            33750.0   \n",
       "1              4          2          2      0.0      5.0            49500.0   \n",
       "2             12          1          3      1.0     10.0            20454.0   \n",
       "3              5          8          3      3.0      1.0             5472.0   \n",
       "4              5          9          1      2.0      2.0             6057.0   \n",
       "...          ...        ...        ...      ...      ...                ...   \n",
       "26452          5          5          1      0.0      2.0           112500.0   \n",
       "26453          6          9          2      3.0     11.0             3829.0   \n",
       "26454          5          6          1      2.0      1.0            11700.0   \n",
       "26455          0          3          2      4.0     11.0             2898.0   \n",
       "26456          2          9          1      0.0      9.0             9000.0   \n",
       "\n",
       "                            Owner  Annual_income_r  DAYS_BIRTH_r  \\\n",
       "0      02025000112138994709000130              1.0           2.0   \n",
       "1       0247500040111380154000181              1.0           2.0   \n",
       "2      14500004111190874434010102              2.0           4.0   \n",
       "3      02025000411150882092010161              1.0           3.0   \n",
       "4      01575002111150372105000102              0.0           3.0   \n",
       "...                           ...              ...           ...   \n",
       "26452   0225000241112079198400030              1.0           2.0   \n",
       "26453  01800004121152912475000131              1.0           3.0   \n",
       "26454   0292500440510082201500031              1.0           1.0   \n",
       "26455    117100042311014510700081              0.0           1.0   \n",
       "26456   0810004401195691013000180              0.0           4.0   \n",
       "\n",
       "       working_day_r      Owner_r  \n",
       "0                5.0  00112000130  \n",
       "1                2.0   0040100181  \n",
       "2                5.0  14111010102  \n",
       "3                3.0  00411010161  \n",
       "4                3.0  02111000102  \n",
       "...              ...          ...  \n",
       "26452            3.0   0241100030  \n",
       "26453            3.0  04121000131  \n",
       "26454            3.0   0440500031  \n",
       "26455            0.0   1423100081  \n",
       "26456            1.0  04401000180  \n",
       "\n",
       "[26457 rows x 29 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Owner_r** LabelEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product 함수로 모든 가능한 경우의 수를 계산\n",
    "all_l = list(product(*all_l))\n",
    "for i in range(len(all_l)):\n",
    "    all_l[i] = ''.join([str(j) for j in all_l[i]])\n",
    "\n",
    "# Owner_r 변수 LabelEncoding\n",
    "e = LabelEncoder()\n",
    "e.fit(all_l)\n",
    "train_data['Owner_r'] = e.transform(train_data['Owner_r'])\n",
    "test_data['Owner_r'] = e.transform(test_data['Owner_r'])\n",
    "\n",
    "# categorical columns에 Owner와 Owner_r 추가\n",
    "cate_col.append('Owner')\n",
    "cate_col.append('Owner_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>income_type</th>\n",
       "      <th>Education</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>working_day</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>car_reality</th>\n",
       "      <th>not_working_day</th>\n",
       "      <th>age_y</th>\n",
       "      <th>age_m</th>\n",
       "      <th>age_w</th>\n",
       "      <th>working_y</th>\n",
       "      <th>working_m</th>\n",
       "      <th>working_w</th>\n",
       "      <th>begin_y</th>\n",
       "      <th>begin_m</th>\n",
       "      <th>begin_prop_income</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Annual_income_r</th>\n",
       "      <th>DAYS_BIRTH_r</th>\n",
       "      <th>working_day_r</th>\n",
       "      <th>Owner_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13899</td>\n",
       "      <td>4709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9190</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33750.0</td>\n",
       "      <td>02025000112138994709000130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11380</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9840</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>0247500040111380154000181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19087</td>\n",
       "      <td>4434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14653</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20454.0</td>\n",
       "      <td>14500004111190874434010102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>665886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15088</td>\n",
       "      <td>2092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12996</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5472.0</td>\n",
       "      <td>02025000411150882092010161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15037</td>\n",
       "      <td>2105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12932</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6057.0</td>\n",
       "      <td>01575002111150372105000102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>161766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26452</th>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12079</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10095</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>0225000241112079198400030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>204999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15291</td>\n",
       "      <td>2475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12816</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>01800004121152912475000131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>308656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26454</th>\n",
       "      <td>0</td>\n",
       "      <td>292500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10082</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8067</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>0292500440510082201500031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>348040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26455</th>\n",
       "      <td>1</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10145</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10038</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>117100042311014510700081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>685975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26456</th>\n",
       "      <td>0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19569</td>\n",
       "      <td>1013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18556</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0810004401195691013000180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>346110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26457 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  Annual_income  income_type  Education  family_type  house_type  \\\n",
       "0           0       202500.0            0          1            1           2   \n",
       "1           0       247500.0            0          4            0           1   \n",
       "2           1       450000.0            4          1            1           1   \n",
       "3           0       202500.0            0          4            1           1   \n",
       "4           0       157500.0            2          1            1           1   \n",
       "...       ...            ...          ...        ...          ...         ...   \n",
       "26452       0       225000.0            2          4            1           1   \n",
       "26453       0       180000.0            4          1            2           1   \n",
       "26454       0       292500.0            4          4            0           5   \n",
       "26455       1       171000.0            4          2            3           1   \n",
       "26456       0        81000.0            4          4            0           1   \n",
       "\n",
       "       DAYS_BIRTH  working_day  work_phone  phone  email  occyp_type  \\\n",
       "0           13899         4709           0      0      0          13   \n",
       "1           11380         1540           0      0      1           8   \n",
       "2           19087         4434           0      1      0          10   \n",
       "3           15088         2092           0      1      0          16   \n",
       "4           15037         2105           0      0      0          10   \n",
       "...           ...          ...         ...    ...    ...         ...   \n",
       "26452       12079         1984           0      0      0           3   \n",
       "26453       15291         2475           0      0      0          13   \n",
       "26454       10082         2015           0      0      0           3   \n",
       "26455       10145          107           0      0      0           8   \n",
       "26456       19569         1013           0      0      0          18   \n",
       "\n",
       "       begin_month  car_reality  not_working_day  age_y  age_m  age_w  \\\n",
       "0              6.0            0             9190     38      0      4   \n",
       "1              5.0            1             9840     31      2      0   \n",
       "2             22.0            2            14653     52      3      2   \n",
       "3             37.0            1            12996     41      4      0   \n",
       "4             26.0            2            12932     41      2      1   \n",
       "...            ...          ...              ...    ...    ...    ...   \n",
       "26452          2.0            0            10095     33      1      0   \n",
       "26453         47.0            1            12816     41     10      3   \n",
       "26454         25.0            1             8067     27      7      2   \n",
       "26455         59.0            1            10038     27      9      2   \n",
       "26456          9.0            0            18556     53      7      2   \n",
       "\n",
       "       working_y  working_m  working_w  begin_y  begin_m  begin_prop_income  \\\n",
       "0             12         10          4      0.0      6.0            33750.0   \n",
       "1              4          2          2      0.0      5.0            49500.0   \n",
       "2             12          1          3      1.0     10.0            20454.0   \n",
       "3              5          8          3      3.0      1.0             5472.0   \n",
       "4              5          9          1      2.0      2.0             6057.0   \n",
       "...          ...        ...        ...      ...      ...                ...   \n",
       "26452          5          5          1      0.0      2.0           112500.0   \n",
       "26453          6          9          2      3.0     11.0             3829.0   \n",
       "26454          5          6          1      2.0      1.0            11700.0   \n",
       "26455          0          3          2      4.0     11.0             2898.0   \n",
       "26456          2          9          1      0.0      9.0             9000.0   \n",
       "\n",
       "                            Owner  Annual_income_r  DAYS_BIRTH_r  \\\n",
       "0      02025000112138994709000130              1.0           2.0   \n",
       "1       0247500040111380154000181              1.0           2.0   \n",
       "2      14500004111190874434010102              2.0           4.0   \n",
       "3      02025000411150882092010161              1.0           3.0   \n",
       "4      01575002111150372105000102              0.0           3.0   \n",
       "...                           ...              ...           ...   \n",
       "26452   0225000241112079198400030              1.0           2.0   \n",
       "26453  01800004121152912475000131              1.0           3.0   \n",
       "26454   0292500440510082201500031              1.0           1.0   \n",
       "26455    117100042311014510700081              0.0           1.0   \n",
       "26456   0810004401195691013000180              0.0           4.0   \n",
       "\n",
       "       working_day_r  Owner_r  \n",
       "0                5.0    18255  \n",
       "1                2.0    58195  \n",
       "2                5.0   665886  \n",
       "3                3.0    61105  \n",
       "4                3.0   161766  \n",
       "...              ...      ...  \n",
       "26452            3.0   204999  \n",
       "26453            3.0   308656  \n",
       "26454            3.0   348040  \n",
       "26455            0.0   685975  \n",
       "26456            1.0   346110  \n",
       "\n",
       "[26457 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numerical 데이터 정규화."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numermic_col:\n",
    "    minmax = StandardScaler()\n",
    "    train_data[col] = minmax.fit_transform(train_data[[col]])\n",
    "    test_data[col] = minmax.transform(test_data[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>Annual_income</th>\n",
       "      <th>income_type</th>\n",
       "      <th>Education</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>working_day</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>car_reality</th>\n",
       "      <th>not_working_day</th>\n",
       "      <th>age_y</th>\n",
       "      <th>age_m</th>\n",
       "      <th>age_w</th>\n",
       "      <th>working_y</th>\n",
       "      <th>working_m</th>\n",
       "      <th>working_w</th>\n",
       "      <th>begin_y</th>\n",
       "      <th>begin_m</th>\n",
       "      <th>begin_prop_income</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Annual_income_r</th>\n",
       "      <th>DAYS_BIRTH_r</th>\n",
       "      <th>working_day_r</th>\n",
       "      <th>Owner_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.149136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.490075</td>\n",
       "      <td>1.059227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.215231</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.939166</td>\n",
       "      <td>-0.452819</td>\n",
       "      <td>-1.641152</td>\n",
       "      <td>1.885986</td>\n",
       "      <td>0.994411</td>\n",
       "      <td>1.427247</td>\n",
       "      <td>2.303833</td>\n",
       "      <td>-1.249606</td>\n",
       "      <td>0.183042</td>\n",
       "      <td>0.628472</td>\n",
       "      <td>02025000112138994709000130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590848</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.089621</td>\n",
       "      <td>-0.277849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.275620</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.805573</td>\n",
       "      <td>-1.060808</td>\n",
       "      <td>-1.064590</td>\n",
       "      <td>-1.315703</td>\n",
       "      <td>-0.250447</td>\n",
       "      <td>-0.705356</td>\n",
       "      <td>0.575713</td>\n",
       "      <td>-1.249606</td>\n",
       "      <td>-0.109147</td>\n",
       "      <td>1.178125</td>\n",
       "      <td>0247500040111380154000181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.578550</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744719</td>\n",
       "      <td>0.943198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.249003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.183634</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>-0.776310</td>\n",
       "      <td>0.285141</td>\n",
       "      <td>0.994411</td>\n",
       "      <td>-0.971932</td>\n",
       "      <td>1.439773</td>\n",
       "      <td>-0.526934</td>\n",
       "      <td>1.351799</td>\n",
       "      <td>0.164461</td>\n",
       "      <td>14500004111190874434010102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>665886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.149136</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.207081</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.656836</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.156926</td>\n",
       "      <td>-0.192253</td>\n",
       "      <td>-0.488029</td>\n",
       "      <td>-1.315703</td>\n",
       "      <td>-0.094839</td>\n",
       "      <td>0.894096</td>\n",
       "      <td>1.439773</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>-1.277904</td>\n",
       "      <td>-0.358389</td>\n",
       "      <td>02025000411150882092010161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.292575</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.219220</td>\n",
       "      <td>-0.039462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.007446</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.170080</td>\n",
       "      <td>-0.192253</td>\n",
       "      <td>-1.064590</td>\n",
       "      <td>-0.515281</td>\n",
       "      <td>-0.094839</td>\n",
       "      <td>1.160672</td>\n",
       "      <td>-0.288347</td>\n",
       "      <td>0.195739</td>\n",
       "      <td>-0.985715</td>\n",
       "      <td>-0.337974</td>\n",
       "      <td>01575002111150372105000102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>161766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26452</th>\n",
       "      <td>0</td>\n",
       "      <td>0.369992</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.923252</td>\n",
       "      <td>-0.090515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.456788</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.753163</td>\n",
       "      <td>-0.887097</td>\n",
       "      <td>-1.352871</td>\n",
       "      <td>-1.315703</td>\n",
       "      <td>-0.094839</td>\n",
       "      <td>0.094370</td>\n",
       "      <td>-0.288347</td>\n",
       "      <td>-1.249606</td>\n",
       "      <td>-0.985715</td>\n",
       "      <td>3.376734</td>\n",
       "      <td>0225000241112079198400030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>204999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.071719</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.158765</td>\n",
       "      <td>0.116649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.260729</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.193921</td>\n",
       "      <td>-0.192253</td>\n",
       "      <td>1.241654</td>\n",
       "      <td>1.085563</td>\n",
       "      <td>0.060768</td>\n",
       "      <td>1.160672</td>\n",
       "      <td>0.575713</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>1.643988</td>\n",
       "      <td>-0.415728</td>\n",
       "      <td>01800004121152912475000131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>308656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26454</th>\n",
       "      <td>0</td>\n",
       "      <td>1.032559</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.398558</td>\n",
       "      <td>-0.077435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.067835</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.169974</td>\n",
       "      <td>-1.408230</td>\n",
       "      <td>0.376812</td>\n",
       "      <td>0.285141</td>\n",
       "      <td>-0.094839</td>\n",
       "      <td>0.360945</td>\n",
       "      <td>-0.288347</td>\n",
       "      <td>0.195739</td>\n",
       "      <td>-1.277904</td>\n",
       "      <td>-0.141041</td>\n",
       "      <td>0292500440510082201500031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>348040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26455</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.160062</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.383563</td>\n",
       "      <td>-0.882466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.985400</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.764878</td>\n",
       "      <td>-1.408230</td>\n",
       "      <td>0.953373</td>\n",
       "      <td>0.285141</td>\n",
       "      <td>-0.872875</td>\n",
       "      <td>-0.438781</td>\n",
       "      <td>0.575713</td>\n",
       "      <td>1.641085</td>\n",
       "      <td>1.643988</td>\n",
       "      <td>-0.448218</td>\n",
       "      <td>117100042311014510700081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>685975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26456</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.043485</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859440</td>\n",
       "      <td>-0.500203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.034063</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985811</td>\n",
       "      <td>0.850013</td>\n",
       "      <td>0.376812</td>\n",
       "      <td>0.285141</td>\n",
       "      <td>-0.561661</td>\n",
       "      <td>1.160672</td>\n",
       "      <td>-0.288347</td>\n",
       "      <td>-1.249606</td>\n",
       "      <td>1.059610</td>\n",
       "      <td>-0.235267</td>\n",
       "      <td>0810004401195691013000180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>346110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26457 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  Annual_income  income_type  Education  family_type  house_type  \\\n",
       "0           0       0.149136            0          1            1           2   \n",
       "1           0       0.590848            0          4            0           1   \n",
       "2           1       2.578550            4          1            1           1   \n",
       "3           0       0.149136            0          4            1           1   \n",
       "4           0      -0.292575            2          1            1           1   \n",
       "...       ...            ...          ...        ...          ...         ...   \n",
       "26452       0       0.369992            2          4            1           1   \n",
       "26453       0      -0.071719            4          1            2           1   \n",
       "26454       0       1.032559            4          4            0           5   \n",
       "26455       1      -0.160062            4          2            3           1   \n",
       "26456       0      -1.043485            4          4            0           1   \n",
       "\n",
       "       DAYS_BIRTH  working_day  work_phone  phone  email  occyp_type  \\\n",
       "0       -0.490075     1.059227           0      0      0          13   \n",
       "1       -1.089621    -0.277849           0      0      1           8   \n",
       "2        0.744719     0.943198           0      1      0          10   \n",
       "3       -0.207081    -0.044947           0      1      0          16   \n",
       "4       -0.219220    -0.039462           0      0      0          10   \n",
       "...           ...          ...         ...    ...    ...         ...   \n",
       "26452   -0.923252    -0.090515           0      0      0           3   \n",
       "26453   -0.158765     0.116649           0      0      0          13   \n",
       "26454   -1.398558    -0.077435           0      0      0           3   \n",
       "26455   -1.383563    -0.882466           0      0      0           8   \n",
       "26456    0.859440    -0.500203           0      0      0          18   \n",
       "\n",
       "       begin_month  car_reality  not_working_day     age_y     age_m  \\\n",
       "0        -1.215231            0        -0.939166 -0.452819 -1.641152   \n",
       "1        -1.275620            1        -0.805573 -1.060808 -1.064590   \n",
       "2        -0.249003            2         0.183634  0.763158 -0.776310   \n",
       "3         0.656836            1        -0.156926 -0.192253 -0.488029   \n",
       "4        -0.007446            2        -0.170080 -0.192253 -1.064590   \n",
       "...            ...          ...              ...       ...       ...   \n",
       "26452    -1.456788            0        -0.753163 -0.887097 -1.352871   \n",
       "26453     1.260729            1        -0.193921 -0.192253  1.241654   \n",
       "26454    -0.067835            1        -1.169974 -1.408230  0.376812   \n",
       "26455     1.985400            1        -0.764878 -1.408230  0.953373   \n",
       "26456    -1.034063            0         0.985811  0.850013  0.376812   \n",
       "\n",
       "          age_w  working_y  working_m  working_w   begin_y   begin_m  \\\n",
       "0      1.885986   0.994411   1.427247   2.303833 -1.249606  0.183042   \n",
       "1     -1.315703  -0.250447  -0.705356   0.575713 -1.249606 -0.109147   \n",
       "2      0.285141   0.994411  -0.971932   1.439773 -0.526934  1.351799   \n",
       "3     -1.315703  -0.094839   0.894096   1.439773  0.918412 -1.277904   \n",
       "4     -0.515281  -0.094839   1.160672  -0.288347  0.195739 -0.985715   \n",
       "...         ...        ...        ...        ...       ...       ...   \n",
       "26452 -1.315703  -0.094839   0.094370  -0.288347 -1.249606 -0.985715   \n",
       "26453  1.085563   0.060768   1.160672   0.575713  0.918412  1.643988   \n",
       "26454  0.285141  -0.094839   0.360945  -0.288347  0.195739 -1.277904   \n",
       "26455  0.285141  -0.872875  -0.438781   0.575713  1.641085  1.643988   \n",
       "26456  0.285141  -0.561661   1.160672  -0.288347 -1.249606  1.059610   \n",
       "\n",
       "       begin_prop_income                       Owner  Annual_income_r  \\\n",
       "0               0.628472  02025000112138994709000130              1.0   \n",
       "1               1.178125   0247500040111380154000181              1.0   \n",
       "2               0.164461  14500004111190874434010102              2.0   \n",
       "3              -0.358389  02025000411150882092010161              1.0   \n",
       "4              -0.337974  01575002111150372105000102              0.0   \n",
       "...                  ...                         ...              ...   \n",
       "26452           3.376734   0225000241112079198400030              1.0   \n",
       "26453          -0.415728  01800004121152912475000131              1.0   \n",
       "26454          -0.141041   0292500440510082201500031              1.0   \n",
       "26455          -0.448218    117100042311014510700081              0.0   \n",
       "26456          -0.235267   0810004401195691013000180              0.0   \n",
       "\n",
       "       DAYS_BIRTH_r  working_day_r  Owner_r  \n",
       "0               2.0            5.0    18255  \n",
       "1               2.0            2.0    58195  \n",
       "2               4.0            5.0   665886  \n",
       "3               3.0            3.0    61105  \n",
       "4               3.0            3.0   161766  \n",
       "...             ...            ...      ...  \n",
       "26452           2.0            3.0   204999  \n",
       "26453           3.0            3.0   308656  \n",
       "26454           1.0            3.0   348040  \n",
       "26455           1.0            0.0   685975  \n",
       "26456           4.0            1.0   346110  \n",
       "\n",
       "[26457 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "과적합을 최소화 하기 위해 **CV Stacking** 사용.  \n",
    "**CatBoostClassifier, XGBClassifier, RandomForestClassifier, LGBMClassifier**로 학습시킨 뒤, 결과를 합쳐 **LGBMClassifier**로 한번더 학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier, RandomForestClassifier, LGBMClassifier에서 사용할 데이터\n",
    "X = train_data.drop(['Owner'], axis=1)\n",
    "y = train_data_y\n",
    "X_test = test_data.drop(['Owner'], axis=1)\n",
    "categorical_columns = copy.deepcopy(cate_col)\n",
    "categorical_columns.remove('Owner')\n",
    "\n",
    "# CatBoostClassifier에서 사용할 데이터\n",
    "X_cat = train_data.drop(['Owner_r'], axis=1)\n",
    "y_cat = train_data_y\n",
    "X_test_cat = test_data.drop(['Owner_r'], axis=1)\n",
    "categorical_columns_cat = copy.deepcopy(cate_col)\n",
    "categorical_columns_cat.remove('Owner_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 로딩\n",
    "**optuna**로 튜닝. CatBoostClassifier 튜닝을 하지 않은 모델이 성능이 더 좋아서 튜닝 x.\n",
    "\n",
    "#### LGBMClassifier 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.015,\n",
       " 'objective': 'multiclass',\n",
       " 'n_jobs': 12,\n",
       " 'metric': 'multi_logloss',\n",
       " 'device_type': 'cuda',\n",
       " 'random_state': 1234,\n",
       " 'n_estimators': 100000,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'bagging_freq': 19,\n",
       " 'bagging_fraction': 0.8361499274257655,\n",
       " 'max_depth': 9,\n",
       " 'min_data_in_leaf': 5,\n",
       " 'colsample_bytree': 0.5545131276302593,\n",
       " 'reg_alpha': 5.442681671789194,\n",
       " 'reg_lambda': 0.2525850918547932,\n",
       " 'max_bin': 131,\n",
       " 'num_leaves': 307}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_lgbm = {}\n",
    "with open('./data/params/best_param_lgbm', 'rb') as f:\n",
    "    param_lgbm = pickle.load(f)\n",
    "param_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.2065804393547938,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 0,\n",
       " 'colsample_bytree': 0.6736188784034954,\n",
       " 'reg_alpha': 2.040292632111543,\n",
       " 'reg_lambda': 0.6260501553667925,\n",
       " 'grow_policy': 'lossguide',\n",
       " 'subsample': 0.8393160499864659,\n",
       " 'max_leaves': 205,\n",
       " 'learning_rate': 0.015,\n",
       " 'n_jobs': 12,\n",
       " 'n_estimators': 80000,\n",
       " 'random_state': 1234,\n",
       " 'booster': 'gbtree',\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'objective': 'multi:softmax',\n",
       " 'use_label_encoder': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_xgb = {}\n",
    "with open('./data/params/best_param_xgb', 'rb') as f:\n",
    "    param_xgb = pickle.load(f)\n",
    "param_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 252,\n",
       " 'max_depth': 26,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'random_state': 540}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_rf = {}\n",
    "with open('./data/params/best_param_rf', 'rb') as f:\n",
    "    param_rf = pickle.load(f)\n",
    "param_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 학습에 사용할 LGBMClassifier 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.015,\n",
       " 'objective': 'multiclass',\n",
       " 'n_jobs': 12,\n",
       " 'metric': 'multi_logloss',\n",
       " 'device_type': 'cuda',\n",
       " 'random_state': 1234,\n",
       " 'n_estimators': 100000,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'bagging_freq': 14,\n",
       " 'bagging_fraction': 0.8957366717057349,\n",
       " 'max_depth': 8,\n",
       " 'min_data_in_leaf': 617,\n",
       " 'colsample_bytree': 0.4185219684831536,\n",
       " 'reg_alpha': 21.574874226018196,\n",
       " 'reg_lambda': 0.45933281999458775,\n",
       " 'max_bin': 102,\n",
       " 'num_leaves': 154}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_lgbm_last = {}\n",
    "with open('./data/params/best_param_lgbm_stacked', 'rb') as f:\n",
    "    param_lgbm_last = pickle.load(f)\n",
    "param_lgbm_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(n_folds):\n",
    "    # CV 적용\n",
    "    folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=4558)\n",
    "    splits = folds.split(X_cat, y_cat)\n",
    "    cat_val = np.zeros((X_cat.shape[0], 3))\n",
    "    cat_test = np.zeros((X_test_cat.shape[0], 3))\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f\"-----------Catboost {fold}번-----------\")\n",
    "        # 학습, 검증 셋 나누기\n",
    "        X_train, X_valid = X_cat.iloc[train_idx], X_cat.iloc[valid_idx]\n",
    "        y_train, y_valid = y_cat.iloc[train_idx], y_cat.iloc[valid_idx]\n",
    "        \n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=categorical_columns_cat)\n",
    "        valid_data = Pool(data=X_valid, label=y_valid, cat_features=categorical_columns_cat)\n",
    "\n",
    "        # 모델 학습\n",
    "        model = CatBoostClassifier(n_estimators=10000)\n",
    "        model.fit(train_data, eval_set=valid_data, early_stopping_rounds=100, verbose=50, use_best_model=True)\n",
    "\n",
    "        # 모델 예측값 저장\n",
    "        cat_val[valid_idx] = model.predict_proba(X_valid)\n",
    "        cat_test += model.predict_proba(X_test_cat) / n_folds\n",
    "\n",
    "    log_score = log_loss(y_cat, cat_val)\n",
    "    print(f\"Catboost Log Loss Score: {log_score:.5f}\\n\")\n",
    "    return cat_val, cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Catboost 0번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0710752\ttest: 1.0710582\tbest: 1.0710582 (0)\ttotal: 62ms\tremaining: 10m 19s\n",
      "50:\tlearn: 0.7352424\ttest: 0.6858323\tbest: 0.6858323 (50)\ttotal: 551ms\tremaining: 1m 47s\n",
      "100:\tlearn: 0.7184249\ttest: 0.6614029\tbest: 0.6614029 (100)\ttotal: 1.13s\tremaining: 1m 51s\n",
      "150:\tlearn: 0.7124352\ttest: 0.6567157\tbest: 0.6567157 (150)\ttotal: 1.73s\tremaining: 1m 53s\n",
      "200:\tlearn: 0.7079899\ttest: 0.6538627\tbest: 0.6538627 (200)\ttotal: 2.35s\tremaining: 1m 54s\n",
      "250:\tlearn: 0.7029737\ttest: 0.6519333\tbest: 0.6519333 (250)\ttotal: 3.02s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.6989341\ttest: 0.6512645\tbest: 0.6512203 (295)\ttotal: 3.7s\tremaining: 1m 59s\n",
      "350:\tlearn: 0.6950078\ttest: 0.6507418\tbest: 0.6506553 (336)\ttotal: 4.38s\tremaining: 2m\n",
      "400:\tlearn: 0.6917447\ttest: 0.6502265\tbest: 0.6501992 (391)\ttotal: 5.06s\tremaining: 2m 1s\n",
      "450:\tlearn: 0.6880769\ttest: 0.6503899\tbest: 0.6501921 (401)\ttotal: 5.75s\tremaining: 2m 1s\n",
      "500:\tlearn: 0.6841970\ttest: 0.6502675\tbest: 0.6501583 (475)\ttotal: 6.43s\tremaining: 2m 1s\n",
      "550:\tlearn: 0.6802397\ttest: 0.6500735\tbest: 0.6500040 (544)\ttotal: 7.12s\tremaining: 2m 2s\n",
      "600:\tlearn: 0.6768963\ttest: 0.6500267\tbest: 0.6499549 (583)\ttotal: 7.81s\tremaining: 2m 2s\n",
      "650:\tlearn: 0.6733203\ttest: 0.6500537\tbest: 0.6499549 (583)\ttotal: 8.51s\tremaining: 2m 2s\n",
      "700:\tlearn: 0.6695230\ttest: 0.6500124\tbest: 0.6498685 (681)\ttotal: 9.2s\tremaining: 2m 2s\n",
      "750:\tlearn: 0.6659331\ttest: 0.6499932\tbest: 0.6498098 (742)\ttotal: 9.89s\tremaining: 2m 1s\n",
      "800:\tlearn: 0.6622618\ttest: 0.6501100\tbest: 0.6498098 (742)\ttotal: 10.6s\tremaining: 2m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6498098274\n",
      "bestIteration = 742\n",
      "\n",
      "Shrink model to first 743 iterations.\n",
      "-----------Catboost 1번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0711333\ttest: 1.0710172\tbest: 1.0710172 (0)\ttotal: 15.6ms\tremaining: 2m 36s\n",
      "50:\tlearn: 0.7363475\ttest: 0.6975979\tbest: 0.6975979 (50)\ttotal: 526ms\tremaining: 1m 42s\n",
      "100:\tlearn: 0.7175850\ttest: 0.6748431\tbest: 0.6748431 (100)\ttotal: 1.1s\tremaining: 1m 47s\n",
      "150:\tlearn: 0.7117685\ttest: 0.6715559\tbest: 0.6715126 (147)\ttotal: 1.75s\tremaining: 1m 53s\n",
      "200:\tlearn: 0.7078479\ttest: 0.6709143\tbest: 0.6708626 (176)\ttotal: 2.37s\tremaining: 1m 55s\n",
      "250:\tlearn: 0.7031949\ttest: 0.6697177\tbest: 0.6697177 (250)\ttotal: 3.05s\tremaining: 1m 58s\n",
      "300:\tlearn: 0.6985168\ttest: 0.6686966\tbest: 0.6686966 (300)\ttotal: 3.73s\tremaining: 2m\n",
      "350:\tlearn: 0.6943906\ttest: 0.6687037\tbest: 0.6683471 (317)\ttotal: 4.39s\tremaining: 2m\n",
      "400:\tlearn: 0.6904906\ttest: 0.6682900\tbest: 0.6682814 (399)\ttotal: 5.07s\tremaining: 2m 1s\n",
      "450:\tlearn: 0.6868646\ttest: 0.6680639\tbest: 0.6680639 (450)\ttotal: 5.75s\tremaining: 2m 1s\n",
      "500:\tlearn: 0.6830890\ttest: 0.6681347\tbest: 0.6678866 (472)\ttotal: 6.43s\tremaining: 2m 1s\n",
      "550:\tlearn: 0.6797689\ttest: 0.6677689\tbest: 0.6677658 (547)\ttotal: 7.12s\tremaining: 2m 2s\n",
      "600:\tlearn: 0.6763920\ttest: 0.6673096\tbest: 0.6671898 (584)\ttotal: 7.8s\tremaining: 2m 2s\n",
      "650:\tlearn: 0.6726042\ttest: 0.6672560\tbest: 0.6671898 (584)\ttotal: 8.49s\tremaining: 2m 1s\n",
      "700:\tlearn: 0.6691738\ttest: 0.6671902\tbest: 0.6671323 (682)\ttotal: 9.18s\tremaining: 2m 1s\n",
      "750:\tlearn: 0.6652809\ttest: 0.6676597\tbest: 0.6671323 (682)\ttotal: 9.88s\tremaining: 2m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6671322567\n",
      "bestIteration = 682\n",
      "\n",
      "Shrink model to first 683 iterations.\n",
      "-----------Catboost 2번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0710546\ttest: 1.0716182\tbest: 1.0716182 (0)\ttotal: 15.8ms\tremaining: 2m 37s\n",
      "50:\tlearn: 0.7355436\ttest: 0.6988033\tbest: 0.6988033 (50)\ttotal: 530ms\tremaining: 1m 43s\n",
      "100:\tlearn: 0.7183223\ttest: 0.6732942\tbest: 0.6732942 (100)\ttotal: 1.09s\tremaining: 1m 46s\n",
      "150:\tlearn: 0.7130812\ttest: 0.6700279\tbest: 0.6700279 (150)\ttotal: 1.73s\tremaining: 1m 52s\n",
      "200:\tlearn: 0.7083881\ttest: 0.6674093\tbest: 0.6674054 (198)\ttotal: 2.39s\tremaining: 1m 56s\n",
      "250:\tlearn: 0.7042404\ttest: 0.6660498\tbest: 0.6660498 (250)\ttotal: 3.07s\tremaining: 1m 59s\n",
      "300:\tlearn: 0.7001371\ttest: 0.6650834\tbest: 0.6650834 (300)\ttotal: 3.75s\tremaining: 2m\n",
      "350:\tlearn: 0.6961372\ttest: 0.6644836\tbest: 0.6644206 (348)\ttotal: 4.45s\tremaining: 2m 2s\n",
      "400:\tlearn: 0.6925832\ttest: 0.6636398\tbest: 0.6635902 (399)\ttotal: 5.12s\tremaining: 2m 2s\n",
      "450:\tlearn: 0.6886603\ttest: 0.6629020\tbest: 0.6629012 (449)\ttotal: 5.81s\tremaining: 2m 2s\n",
      "500:\tlearn: 0.6849291\ttest: 0.6625302\tbest: 0.6624886 (494)\ttotal: 6.51s\tremaining: 2m 3s\n",
      "550:\tlearn: 0.6809829\ttest: 0.6623015\tbest: 0.6622580 (537)\ttotal: 7.19s\tremaining: 2m 3s\n",
      "600:\tlearn: 0.6773225\ttest: 0.6622358\tbest: 0.6621402 (590)\ttotal: 7.89s\tremaining: 2m 3s\n",
      "650:\tlearn: 0.6731374\ttest: 0.6617383\tbest: 0.6617124 (649)\ttotal: 8.57s\tremaining: 2m 3s\n",
      "700:\tlearn: 0.6693840\ttest: 0.6615075\tbest: 0.6614655 (688)\ttotal: 9.27s\tremaining: 2m 2s\n",
      "750:\tlearn: 0.6656767\ttest: 0.6613585\tbest: 0.6613079 (728)\ttotal: 9.95s\tremaining: 2m 2s\n",
      "800:\tlearn: 0.6619794\ttest: 0.6610119\tbest: 0.6609800 (795)\ttotal: 10.7s\tremaining: 2m 2s\n",
      "850:\tlearn: 0.6580880\ttest: 0.6612247\tbest: 0.6609539 (833)\ttotal: 11.3s\tremaining: 2m 2s\n",
      "900:\tlearn: 0.6545399\ttest: 0.6610872\tbest: 0.6608914 (873)\ttotal: 12.1s\tremaining: 2m 1s\n",
      "950:\tlearn: 0.6507112\ttest: 0.6613493\tbest: 0.6608914 (873)\ttotal: 12.7s\tremaining: 2m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6608914229\n",
      "bestIteration = 873\n",
      "\n",
      "Shrink model to first 874 iterations.\n",
      "-----------Catboost 3번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0714496\ttest: 1.0717342\tbest: 1.0717342 (0)\ttotal: 13.7ms\tremaining: 2m 16s\n",
      "50:\tlearn: 0.7351926\ttest: 0.7154168\tbest: 0.7154168 (50)\ttotal: 491ms\tremaining: 1m 35s\n",
      "100:\tlearn: 0.7170712\ttest: 0.6935182\tbest: 0.6935182 (100)\ttotal: 1s\tremaining: 1m 38s\n",
      "150:\tlearn: 0.7119460\ttest: 0.6907514\tbest: 0.6907514 (150)\ttotal: 1.62s\tremaining: 1m 45s\n",
      "200:\tlearn: 0.7070699\ttest: 0.6893098\tbest: 0.6892635 (199)\ttotal: 2.27s\tremaining: 1m 50s\n",
      "250:\tlearn: 0.7024889\ttest: 0.6882349\tbest: 0.6882349 (250)\ttotal: 2.94s\tremaining: 1m 54s\n",
      "300:\tlearn: 0.6983342\ttest: 0.6872553\tbest: 0.6872553 (300)\ttotal: 3.61s\tremaining: 1m 56s\n",
      "350:\tlearn: 0.6942472\ttest: 0.6867417\tbest: 0.6865876 (324)\ttotal: 4.3s\tremaining: 1m 58s\n",
      "400:\tlearn: 0.6905116\ttest: 0.6864117\tbest: 0.6863891 (395)\ttotal: 5.03s\tremaining: 2m\n",
      "450:\tlearn: 0.6866418\ttest: 0.6857262\tbest: 0.6856762 (445)\ttotal: 5.7s\tremaining: 2m\n",
      "500:\tlearn: 0.6832056\ttest: 0.6855885\tbest: 0.6855882 (499)\ttotal: 6.38s\tremaining: 2m\n",
      "550:\tlearn: 0.6792677\ttest: 0.6858468\tbest: 0.6853486 (519)\ttotal: 7.06s\tremaining: 2m 1s\n",
      "600:\tlearn: 0.6757002\ttest: 0.6852635\tbest: 0.6852635 (600)\ttotal: 7.74s\tremaining: 2m 1s\n",
      "650:\tlearn: 0.6721908\ttest: 0.6846707\tbest: 0.6846707 (650)\ttotal: 8.42s\tremaining: 2m\n",
      "700:\tlearn: 0.6684352\ttest: 0.6849092\tbest: 0.6846707 (650)\ttotal: 9.12s\tremaining: 2m\n",
      "750:\tlearn: 0.6643580\ttest: 0.6845059\tbest: 0.6844208 (726)\ttotal: 9.81s\tremaining: 2m\n",
      "800:\tlearn: 0.6605157\ttest: 0.6847896\tbest: 0.6844208 (726)\ttotal: 10.5s\tremaining: 2m\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6844207837\n",
      "bestIteration = 726\n",
      "\n",
      "Shrink model to first 727 iterations.\n",
      "-----------Catboost 4번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0710788\ttest: 1.0714909\tbest: 1.0714909 (0)\ttotal: 14.8ms\tremaining: 2m 28s\n",
      "50:\tlearn: 0.7361177\ttest: 0.6961425\tbest: 0.6961425 (50)\ttotal: 470ms\tremaining: 1m 31s\n",
      "100:\tlearn: 0.7177685\ttest: 0.6666201\tbest: 0.6666201 (100)\ttotal: 1.03s\tremaining: 1m 40s\n",
      "150:\tlearn: 0.7124561\ttest: 0.6627201\tbest: 0.6626928 (145)\ttotal: 1.65s\tremaining: 1m 47s\n",
      "200:\tlearn: 0.7084161\ttest: 0.6614429\tbest: 0.6614244 (187)\ttotal: 2.32s\tremaining: 1m 53s\n",
      "250:\tlearn: 0.7041858\ttest: 0.6594571\tbest: 0.6593749 (249)\ttotal: 2.99s\tremaining: 1m 56s\n",
      "300:\tlearn: 0.7001054\ttest: 0.6580446\tbest: 0.6580446 (300)\ttotal: 3.66s\tremaining: 1m 57s\n",
      "350:\tlearn: 0.6964679\ttest: 0.6575801\tbest: 0.6575632 (348)\ttotal: 4.35s\tremaining: 1m 59s\n",
      "400:\tlearn: 0.6926531\ttest: 0.6565917\tbest: 0.6565917 (400)\ttotal: 5.03s\tremaining: 2m\n",
      "450:\tlearn: 0.6887973\ttest: 0.6557262\tbest: 0.6557262 (450)\ttotal: 5.72s\tremaining: 2m 1s\n",
      "500:\tlearn: 0.6854450\ttest: 0.6549184\tbest: 0.6549184 (500)\ttotal: 6.4s\tremaining: 2m 1s\n",
      "550:\tlearn: 0.6814736\ttest: 0.6548919\tbest: 0.6547758 (520)\ttotal: 7.11s\tremaining: 2m 1s\n",
      "600:\tlearn: 0.6779428\ttest: 0.6550070\tbest: 0.6546918 (569)\ttotal: 7.79s\tremaining: 2m 1s\n",
      "650:\tlearn: 0.6746629\ttest: 0.6550857\tbest: 0.6546918 (569)\ttotal: 8.47s\tremaining: 2m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6546918323\n",
      "bestIteration = 569\n",
      "\n",
      "Shrink model to first 570 iterations.\n",
      "-----------Catboost 5번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0712035\ttest: 1.0705429\tbest: 1.0705429 (0)\ttotal: 15.1ms\tremaining: 2m 31s\n",
      "50:\tlearn: 0.7373692\ttest: 0.6989301\tbest: 0.6989301 (50)\ttotal: 510ms\tremaining: 1m 39s\n",
      "100:\tlearn: 0.7186940\ttest: 0.6749672\tbest: 0.6749672 (100)\ttotal: 1.07s\tremaining: 1m 44s\n",
      "150:\tlearn: 0.7124217\ttest: 0.6703222\tbest: 0.6703222 (150)\ttotal: 1.71s\tremaining: 1m 51s\n",
      "200:\tlearn: 0.7080707\ttest: 0.6686133\tbest: 0.6686133 (200)\ttotal: 2.37s\tremaining: 1m 55s\n",
      "250:\tlearn: 0.7038230\ttest: 0.6676187\tbest: 0.6675606 (242)\ttotal: 3.06s\tremaining: 1m 58s\n",
      "300:\tlearn: 0.7001128\ttest: 0.6672152\tbest: 0.6671164 (292)\ttotal: 3.74s\tremaining: 2m\n",
      "350:\tlearn: 0.6960555\ttest: 0.6666523\tbest: 0.6666523 (350)\ttotal: 4.44s\tremaining: 2m 1s\n",
      "400:\tlearn: 0.6923764\ttest: 0.6668260\tbest: 0.6666010 (352)\ttotal: 5.15s\tremaining: 2m 3s\n",
      "450:\tlearn: 0.6884632\ttest: 0.6666659\tbest: 0.6666010 (352)\ttotal: 5.83s\tremaining: 2m 3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.666600966\n",
      "bestIteration = 352\n",
      "\n",
      "Shrink model to first 353 iterations.\n",
      "-----------Catboost 6번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0711363\ttest: 1.0709896\tbest: 1.0709896 (0)\ttotal: 15.7ms\tremaining: 2m 36s\n",
      "50:\tlearn: 0.7330392\ttest: 0.6979455\tbest: 0.6979455 (50)\ttotal: 497ms\tremaining: 1m 37s\n",
      "100:\tlearn: 0.7158558\ttest: 0.6755689\tbest: 0.6755689 (100)\ttotal: 1.07s\tremaining: 1m 45s\n",
      "150:\tlearn: 0.7098129\ttest: 0.6718540\tbest: 0.6718335 (149)\ttotal: 1.69s\tremaining: 1m 50s\n",
      "200:\tlearn: 0.7059939\ttest: 0.6699347\tbest: 0.6699347 (200)\ttotal: 2.34s\tremaining: 1m 53s\n",
      "250:\tlearn: 0.7013346\ttest: 0.6688180\tbest: 0.6688180 (250)\ttotal: 3.02s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.6967230\ttest: 0.6678908\tbest: 0.6678908 (300)\ttotal: 3.7s\tremaining: 1m 59s\n",
      "350:\tlearn: 0.6928291\ttest: 0.6670699\tbest: 0.6670691 (348)\ttotal: 4.38s\tremaining: 2m\n",
      "400:\tlearn: 0.6887389\ttest: 0.6662638\tbest: 0.6662638 (400)\ttotal: 5.07s\tremaining: 2m 1s\n",
      "450:\tlearn: 0.6848015\ttest: 0.6654759\tbest: 0.6654759 (450)\ttotal: 5.75s\tremaining: 2m 1s\n",
      "500:\tlearn: 0.6815515\ttest: 0.6653170\tbest: 0.6652040 (479)\ttotal: 6.44s\tremaining: 2m 2s\n",
      "550:\tlearn: 0.6776815\ttest: 0.6650871\tbest: 0.6650784 (549)\ttotal: 7.12s\tremaining: 2m 2s\n",
      "600:\tlearn: 0.6736822\ttest: 0.6649193\tbest: 0.6649050 (597)\ttotal: 7.81s\tremaining: 2m 2s\n",
      "650:\tlearn: 0.6702227\ttest: 0.6645324\tbest: 0.6645324 (650)\ttotal: 8.52s\tremaining: 2m 2s\n",
      "700:\tlearn: 0.6668197\ttest: 0.6646901\tbest: 0.6643594 (674)\ttotal: 9.21s\tremaining: 2m 2s\n",
      "750:\tlearn: 0.6635052\ttest: 0.6644207\tbest: 0.6643594 (674)\ttotal: 9.91s\tremaining: 2m 2s\n",
      "800:\tlearn: 0.6602192\ttest: 0.6641526\tbest: 0.6641423 (771)\ttotal: 10.6s\tremaining: 2m 1s\n",
      "850:\tlearn: 0.6564206\ttest: 0.6637663\tbest: 0.6636315 (829)\ttotal: 11.3s\tremaining: 2m 1s\n",
      "900:\tlearn: 0.6527633\ttest: 0.6640220\tbest: 0.6636055 (872)\ttotal: 12s\tremaining: 2m 1s\n",
      "950:\tlearn: 0.6490223\ttest: 0.6639582\tbest: 0.6636055 (872)\ttotal: 12.7s\tremaining: 2m\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6636055306\n",
      "bestIteration = 872\n",
      "\n",
      "Shrink model to first 873 iterations.\n",
      "-----------Catboost 7번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0708885\ttest: 1.0699504\tbest: 1.0699504 (0)\ttotal: 15.8ms\tremaining: 2m 37s\n",
      "50:\tlearn: 0.7363472\ttest: 0.6796648\tbest: 0.6796648 (50)\ttotal: 547ms\tremaining: 1m 46s\n",
      "100:\tlearn: 0.7182846\ttest: 0.6518831\tbest: 0.6518831 (100)\ttotal: 1.16s\tremaining: 1m 53s\n",
      "150:\tlearn: 0.7120429\ttest: 0.6469927\tbest: 0.6469927 (150)\ttotal: 1.78s\tremaining: 1m 56s\n",
      "200:\tlearn: 0.7073885\ttest: 0.6452548\tbest: 0.6452414 (198)\ttotal: 2.43s\tremaining: 1m 58s\n",
      "250:\tlearn: 0.7035682\ttest: 0.6443470\tbest: 0.6443470 (250)\ttotal: 3.12s\tremaining: 2m 1s\n",
      "300:\tlearn: 0.6997917\ttest: 0.6437180\tbest: 0.6437180 (300)\ttotal: 3.81s\tremaining: 2m 2s\n",
      "350:\tlearn: 0.6960181\ttest: 0.6432610\tbest: 0.6432237 (348)\ttotal: 4.5s\tremaining: 2m 3s\n",
      "400:\tlearn: 0.6922134\ttest: 0.6425611\tbest: 0.6425511 (399)\ttotal: 5.2s\tremaining: 2m 4s\n",
      "450:\tlearn: 0.6883989\ttest: 0.6422328\tbest: 0.6422328 (450)\ttotal: 5.89s\tremaining: 2m 4s\n",
      "500:\tlearn: 0.6846692\ttest: 0.6420885\tbest: 0.6420014 (484)\ttotal: 6.58s\tremaining: 2m 4s\n",
      "550:\tlearn: 0.6813053\ttest: 0.6423200\tbest: 0.6419796 (518)\ttotal: 7.28s\tremaining: 2m 4s\n",
      "600:\tlearn: 0.6774454\ttest: 0.6423060\tbest: 0.6419796 (518)\ttotal: 7.98s\tremaining: 2m 4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6419795734\n",
      "bestIteration = 518\n",
      "\n",
      "Shrink model to first 519 iterations.\n",
      "-----------Catboost 8번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0714741\ttest: 1.0715936\tbest: 1.0715936 (0)\ttotal: 14.5ms\tremaining: 2m 25s\n",
      "50:\tlearn: 0.7373838\ttest: 0.6785304\tbest: 0.6785304 (50)\ttotal: 542ms\tremaining: 1m 45s\n",
      "100:\tlearn: 0.7192777\ttest: 0.6476519\tbest: 0.6476519 (100)\ttotal: 1.15s\tremaining: 1m 53s\n",
      "150:\tlearn: 0.7134671\ttest: 0.6422387\tbest: 0.6422387 (150)\ttotal: 1.79s\tremaining: 1m 57s\n",
      "200:\tlearn: 0.7093196\ttest: 0.6397338\tbest: 0.6397338 (200)\ttotal: 2.43s\tremaining: 1m 58s\n",
      "250:\tlearn: 0.7051835\ttest: 0.6389092\tbest: 0.6389092 (250)\ttotal: 3.1s\tremaining: 2m\n",
      "300:\tlearn: 0.7006589\ttest: 0.6380606\tbest: 0.6380357 (299)\ttotal: 3.79s\tremaining: 2m 2s\n",
      "350:\tlearn: 0.6964464\ttest: 0.6374436\tbest: 0.6373869 (333)\ttotal: 4.48s\tremaining: 2m 3s\n",
      "400:\tlearn: 0.6922367\ttest: 0.6369718\tbest: 0.6368784 (395)\ttotal: 5.17s\tremaining: 2m 3s\n",
      "450:\tlearn: 0.6882734\ttest: 0.6362385\tbest: 0.6361620 (448)\ttotal: 5.87s\tremaining: 2m 4s\n",
      "500:\tlearn: 0.6849909\ttest: 0.6363895\tbest: 0.6361603 (457)\ttotal: 6.56s\tremaining: 2m 4s\n",
      "550:\tlearn: 0.6808174\ttest: 0.6359633\tbest: 0.6358048 (537)\ttotal: 7.24s\tremaining: 2m 4s\n",
      "600:\tlearn: 0.6770369\ttest: 0.6358952\tbest: 0.6358048 (537)\ttotal: 7.94s\tremaining: 2m 4s\n",
      "650:\tlearn: 0.6733917\ttest: 0.6359153\tbest: 0.6356483 (626)\ttotal: 8.64s\tremaining: 2m 4s\n",
      "700:\tlearn: 0.6697244\ttest: 0.6358826\tbest: 0.6356337 (678)\ttotal: 9.33s\tremaining: 2m 3s\n",
      "750:\tlearn: 0.6661465\ttest: 0.6363234\tbest: 0.6356337 (678)\ttotal: 10s\tremaining: 2m 3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6356337126\n",
      "bestIteration = 678\n",
      "\n",
      "Shrink model to first 679 iterations.\n",
      "-----------Catboost 9번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0713586\ttest: 1.0723003\tbest: 1.0723003 (0)\ttotal: 13.6ms\tremaining: 2m 16s\n",
      "50:\tlearn: 0.7358239\ttest: 0.7016552\tbest: 0.7016552 (50)\ttotal: 524ms\tremaining: 1m 42s\n",
      "100:\tlearn: 0.7182617\ttest: 0.6745268\tbest: 0.6745268 (100)\ttotal: 1.09s\tremaining: 1m 47s\n",
      "150:\tlearn: 0.7126807\ttest: 0.6703349\tbest: 0.6703349 (150)\ttotal: 1.73s\tremaining: 1m 52s\n",
      "200:\tlearn: 0.7079551\ttest: 0.6680734\tbest: 0.6680734 (200)\ttotal: 2.35s\tremaining: 1m 54s\n",
      "250:\tlearn: 0.7040465\ttest: 0.6669815\tbest: 0.6669815 (250)\ttotal: 3.02s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.6996746\ttest: 0.6665427\tbest: 0.6664471 (292)\ttotal: 3.71s\tremaining: 1m 59s\n",
      "350:\tlearn: 0.6963267\ttest: 0.6661345\tbest: 0.6661345 (350)\ttotal: 4.41s\tremaining: 2m 1s\n",
      "400:\tlearn: 0.6921379\ttest: 0.6655694\tbest: 0.6655574 (398)\ttotal: 5.11s\tremaining: 2m 2s\n",
      "450:\tlearn: 0.6877746\ttest: 0.6657023\tbest: 0.6654119 (411)\ttotal: 5.81s\tremaining: 2m 2s\n",
      "500:\tlearn: 0.6836439\ttest: 0.6656404\tbest: 0.6654119 (411)\ttotal: 6.5s\tremaining: 2m 3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6654119297\n",
      "bestIteration = 411\n",
      "\n",
      "Shrink model to first 412 iterations.\n",
      "-----------Catboost 10번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0707494\ttest: 1.0713187\tbest: 1.0713187 (0)\ttotal: 15.2ms\tremaining: 2m 32s\n",
      "50:\tlearn: 0.7356882\ttest: 0.7090898\tbest: 0.7090898 (50)\ttotal: 520ms\tremaining: 1m 41s\n",
      "100:\tlearn: 0.7158694\ttest: 0.6839158\tbest: 0.6838681 (99)\ttotal: 1.08s\tremaining: 1m 46s\n",
      "150:\tlearn: 0.7102227\ttest: 0.6808458\tbest: 0.6808458 (150)\ttotal: 1.67s\tremaining: 1m 48s\n",
      "200:\tlearn: 0.7056783\ttest: 0.6795068\tbest: 0.6794515 (197)\ttotal: 2.3s\tremaining: 1m 52s\n",
      "250:\tlearn: 0.7011153\ttest: 0.6784661\tbest: 0.6784236 (247)\ttotal: 2.97s\tremaining: 1m 55s\n",
      "300:\tlearn: 0.6969004\ttest: 0.6784338\tbest: 0.6783193 (256)\ttotal: 3.65s\tremaining: 1m 57s\n",
      "350:\tlearn: 0.6927965\ttest: 0.6786759\tbest: 0.6783193 (256)\ttotal: 4.34s\tremaining: 1m 59s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.678319251\n",
      "bestIteration = 256\n",
      "\n",
      "Shrink model to first 257 iterations.\n",
      "-----------Catboost 11번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0707851\ttest: 1.0708604\tbest: 1.0708604 (0)\ttotal: 15.8ms\tremaining: 2m 37s\n",
      "50:\tlearn: 0.7355463\ttest: 0.7033899\tbest: 0.7033899 (50)\ttotal: 541ms\tremaining: 1m 45s\n",
      "100:\tlearn: 0.7158801\ttest: 0.6804584\tbest: 0.6804584 (100)\ttotal: 1.1s\tremaining: 1m 47s\n",
      "150:\tlearn: 0.7096899\ttest: 0.6779308\tbest: 0.6779308 (150)\ttotal: 1.73s\tremaining: 1m 52s\n",
      "200:\tlearn: 0.7060437\ttest: 0.6772153\tbest: 0.6771439 (198)\ttotal: 2.36s\tremaining: 1m 55s\n",
      "250:\tlearn: 0.7016964\ttest: 0.6765333\tbest: 0.6764178 (246)\ttotal: 3.04s\tremaining: 1m 58s\n",
      "300:\tlearn: 0.6976842\ttest: 0.6763533\tbest: 0.6761003 (291)\ttotal: 3.73s\tremaining: 2m\n",
      "350:\tlearn: 0.6934114\ttest: 0.6763316\tbest: 0.6761003 (291)\ttotal: 4.42s\tremaining: 2m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6761003198\n",
      "bestIteration = 291\n",
      "\n",
      "Shrink model to first 292 iterations.\n",
      "-----------Catboost 12번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0714858\ttest: 1.0711703\tbest: 1.0711703 (0)\ttotal: 13.4ms\tremaining: 2m 13s\n",
      "50:\tlearn: 0.7367323\ttest: 0.7045074\tbest: 0.7045074 (50)\ttotal: 511ms\tremaining: 1m 39s\n",
      "100:\tlearn: 0.7175714\ttest: 0.6794989\tbest: 0.6794989 (100)\ttotal: 1.07s\tremaining: 1m 44s\n",
      "150:\tlearn: 0.7115432\ttest: 0.6748277\tbest: 0.6748277 (150)\ttotal: 1.67s\tremaining: 1m 48s\n",
      "200:\tlearn: 0.7073785\ttest: 0.6725436\tbest: 0.6725436 (200)\ttotal: 2.32s\tremaining: 1m 53s\n",
      "250:\tlearn: 0.7027365\ttest: 0.6715841\tbest: 0.6715841 (250)\ttotal: 2.99s\tremaining: 1m 56s\n",
      "300:\tlearn: 0.6985655\ttest: 0.6702926\tbest: 0.6702923 (298)\ttotal: 3.68s\tremaining: 1m 58s\n",
      "350:\tlearn: 0.6945749\ttest: 0.6697501\tbest: 0.6696048 (338)\ttotal: 4.37s\tremaining: 2m\n",
      "400:\tlearn: 0.6907330\ttest: 0.6697762\tbest: 0.6696048 (338)\ttotal: 5.05s\tremaining: 2m\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6696047798\n",
      "bestIteration = 338\n",
      "\n",
      "Shrink model to first 339 iterations.\n",
      "-----------Catboost 13번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0714573\ttest: 1.0709746\tbest: 1.0709746 (0)\ttotal: 13.3ms\tremaining: 2m 12s\n",
      "50:\tlearn: 0.7363626\ttest: 0.7012676\tbest: 0.7012676 (50)\ttotal: 515ms\tremaining: 1m 40s\n",
      "100:\tlearn: 0.7173857\ttest: 0.6776183\tbest: 0.6776183 (100)\ttotal: 1.08s\tremaining: 1m 45s\n",
      "150:\tlearn: 0.7111094\ttest: 0.6737187\tbest: 0.6737187 (150)\ttotal: 1.73s\tremaining: 1m 53s\n",
      "200:\tlearn: 0.7071383\ttest: 0.6724474\tbest: 0.6724025 (198)\ttotal: 2.35s\tremaining: 1m 54s\n",
      "250:\tlearn: 0.7021734\ttest: 0.6709534\tbest: 0.6709234 (249)\ttotal: 3.03s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.6972051\ttest: 0.6702172\tbest: 0.6699863 (291)\ttotal: 3.69s\tremaining: 1m 58s\n",
      "350:\tlearn: 0.6934769\ttest: 0.6702119\tbest: 0.6699863 (291)\ttotal: 4.39s\tremaining: 2m\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6699862678\n",
      "bestIteration = 291\n",
      "\n",
      "Shrink model to first 292 iterations.\n",
      "-----------Catboost 14번-----------\n",
      "Learning rate set to 0.047773\n",
      "0:\tlearn: 1.0714484\ttest: 1.0713603\tbest: 1.0713603 (0)\ttotal: 13.1ms\tremaining: 2m 11s\n",
      "50:\tlearn: 0.7324043\ttest: 0.7003230\tbest: 0.7003230 (50)\ttotal: 539ms\tremaining: 1m 45s\n",
      "100:\tlearn: 0.7155436\ttest: 0.6821089\tbest: 0.6821089 (100)\ttotal: 1.15s\tremaining: 1m 53s\n",
      "150:\tlearn: 0.7099126\ttest: 0.6797405\tbest: 0.6797005 (146)\ttotal: 1.78s\tremaining: 1m 56s\n",
      "200:\tlearn: 0.7055475\ttest: 0.6791829\tbest: 0.6791507 (199)\ttotal: 2.45s\tremaining: 1m 59s\n",
      "250:\tlearn: 0.7004036\ttest: 0.6793161\tbest: 0.6788254 (213)\ttotal: 3.12s\tremaining: 2m 1s\n",
      "300:\tlearn: 0.6961395\ttest: 0.6789580\tbest: 0.6788254 (213)\ttotal: 3.81s\tremaining: 2m 2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6788253847\n",
      "bestIteration = 213\n",
      "\n",
      "Shrink model to first 214 iterations.\n",
      "Catboost Log Loss Score: 0.66420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_folds = 15\n",
    "cat_val, cat_test = train_catboost(n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(n_folds):\n",
    "    folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=4558)\n",
    "    splits = folds.split(X, y)\n",
    "    lgbm_val = np.zeros((X.shape[0], 3))\n",
    "    lgbm_test = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "    param_lgbm['learning_rate'] = 0.25\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f\"-----------LGBM {fold}번-----------\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = LGBMClassifier(**param_lgbm)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "             callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=50)])\n",
    "\n",
    "        lgbm_val[valid_idx] = model.predict_proba(X_valid)\n",
    "        lgbm_test += model.predict_proba(X_test) / n_folds\n",
    "\n",
    "    log_score = log_loss(y, lgbm_val)\n",
    "    print(f\"LGBM Log Loss Score: {log_score:.5f}\\n\")\n",
    "    return lgbm_val, lgbm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------LGBM 0번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.548554\tvalid_1's multi_logloss: 0.725238\n",
      "[100]\ttraining's multi_logloss: 0.442031\tvalid_1's multi_logloss: 0.713716\n",
      "[150]\ttraining's multi_logloss: 0.385336\tvalid_1's multi_logloss: 0.716726\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's multi_logloss: 0.443173\tvalid_1's multi_logloss: 0.713361\n",
      "-----------LGBM 1번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.548399\tvalid_1's multi_logloss: 0.734427\n",
      "[100]\ttraining's multi_logloss: 0.44317\tvalid_1's multi_logloss: 0.731314\n",
      "[150]\ttraining's multi_logloss: 0.385309\tvalid_1's multi_logloss: 0.735627\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's multi_logloss: 0.46428\tvalid_1's multi_logloss: 0.729989\n",
      "-----------LGBM 2번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.544269\tvalid_1's multi_logloss: 0.744241\n",
      "[100]\ttraining's multi_logloss: 0.441328\tvalid_1's multi_logloss: 0.739075\n",
      "[150]\ttraining's multi_logloss: 0.381993\tvalid_1's multi_logloss: 0.743858\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's multi_logloss: 0.471516\tvalid_1's multi_logloss: 0.738176\n",
      "-----------LGBM 3번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.540581\tvalid_1's multi_logloss: 0.741987\n",
      "[100]\ttraining's multi_logloss: 0.439473\tvalid_1's multi_logloss: 0.7387\n",
      "[150]\ttraining's multi_logloss: 0.385258\tvalid_1's multi_logloss: 0.743422\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's multi_logloss: 0.472723\tvalid_1's multi_logloss: 0.737239\n",
      "-----------LGBM 4번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.546388\tvalid_1's multi_logloss: 0.744574\n",
      "[100]\ttraining's multi_logloss: 0.443774\tvalid_1's multi_logloss: 0.733382\n",
      "[150]\ttraining's multi_logloss: 0.385465\tvalid_1's multi_logloss: 0.736221\n",
      "[200]\ttraining's multi_logloss: 0.348634\tvalid_1's multi_logloss: 0.742307\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's multi_logloss: 0.440533\tvalid_1's multi_logloss: 0.732347\n",
      "-----------LGBM 5번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.539595\tvalid_1's multi_logloss: 0.731226\n",
      "[100]\ttraining's multi_logloss: 0.440609\tvalid_1's multi_logloss: 0.730081\n",
      "[150]\ttraining's multi_logloss: 0.385174\tvalid_1's multi_logloss: 0.73402\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's multi_logloss: 0.507788\tvalid_1's multi_logloss: 0.727124\n",
      "-----------LGBM 6번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.549493\tvalid_1's multi_logloss: 0.730476\n",
      "[100]\ttraining's multi_logloss: 0.44399\tvalid_1's multi_logloss: 0.724265\n",
      "[150]\ttraining's multi_logloss: 0.385452\tvalid_1's multi_logloss: 0.729981\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's multi_logloss: 0.48626\tvalid_1's multi_logloss: 0.721579\n",
      "-----------LGBM 7번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.542429\tvalid_1's multi_logloss: 0.709142\n",
      "[100]\ttraining's multi_logloss: 0.441707\tvalid_1's multi_logloss: 0.703543\n",
      "[150]\ttraining's multi_logloss: 0.385534\tvalid_1's multi_logloss: 0.708207\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's multi_logloss: 0.478805\tvalid_1's multi_logloss: 0.699759\n",
      "-----------LGBM 8번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.547418\tvalid_1's multi_logloss: 0.722564\n",
      "[100]\ttraining's multi_logloss: 0.44525\tvalid_1's multi_logloss: 0.70892\n",
      "[150]\ttraining's multi_logloss: 0.386109\tvalid_1's multi_logloss: 0.71185\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's multi_logloss: 0.450737\tvalid_1's multi_logloss: 0.708425\n",
      "-----------LGBM 9번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.544065\tvalid_1's multi_logloss: 0.749161\n",
      "[100]\ttraining's multi_logloss: 0.44157\tvalid_1's multi_logloss: 0.750269\n",
      "[150]\ttraining's multi_logloss: 0.382731\tvalid_1's multi_logloss: 0.753662\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's multi_logloss: 0.466561\tvalid_1's multi_logloss: 0.745863\n",
      "-----------LGBM 10번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.547044\tvalid_1's multi_logloss: 0.762408\n",
      "[100]\ttraining's multi_logloss: 0.440393\tvalid_1's multi_logloss: 0.763174\n",
      "[150]\ttraining's multi_logloss: 0.383591\tvalid_1's multi_logloss: 0.771789\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's multi_logloss: 0.501174\tvalid_1's multi_logloss: 0.757018\n",
      "-----------LGBM 11번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.544995\tvalid_1's multi_logloss: 0.765538\n",
      "[100]\ttraining's multi_logloss: 0.439515\tvalid_1's multi_logloss: 0.765287\n",
      "[150]\ttraining's multi_logloss: 0.384831\tvalid_1's multi_logloss: 0.776295\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's multi_logloss: 0.497369\tvalid_1's multi_logloss: 0.760403\n",
      "-----------LGBM 12번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.55136\tvalid_1's multi_logloss: 0.728725\n",
      "[100]\ttraining's multi_logloss: 0.444055\tvalid_1's multi_logloss: 0.727977\n",
      "[150]\ttraining's multi_logloss: 0.386738\tvalid_1's multi_logloss: 0.731714\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's multi_logloss: 0.498262\tvalid_1's multi_logloss: 0.723345\n",
      "-----------LGBM 13번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.545578\tvalid_1's multi_logloss: 0.746237\n",
      "[100]\ttraining's multi_logloss: 0.44195\tvalid_1's multi_logloss: 0.752497\n",
      "[150]\ttraining's multi_logloss: 0.384018\tvalid_1's multi_logloss: 0.762609\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's multi_logloss: 0.530734\tvalid_1's multi_logloss: 0.745024\n",
      "-----------LGBM 14번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8361499274257655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8361499274257655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's multi_logloss: 0.540579\tvalid_1's multi_logloss: 0.737458\n",
      "[100]\ttraining's multi_logloss: 0.440976\tvalid_1's multi_logloss: 0.734725\n",
      "[150]\ttraining's multi_logloss: 0.384003\tvalid_1's multi_logloss: 0.734901\n",
      "[200]\ttraining's multi_logloss: 0.348582\tvalid_1's multi_logloss: 0.740353\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's multi_logloss: 0.41883\tvalid_1's multi_logloss: 0.732479\n",
      "LGBM Log Loss Score: 0.73148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_val, lgbm_test = train_lgbm(n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(n_folds):\n",
    "    folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=4558)\n",
    "    splits = folds.split(X, y)\n",
    "    xgb_val = np.zeros((X.shape[0], 3))\n",
    "    xgb_test = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f\"-----------XGB {fold}번-----------\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = XGBClassifier(**param_xgb)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              early_stopping_rounds=100, verbose=500, eval_metric='mlogloss')\n",
    "\n",
    "        xgb_val[valid_idx] = model.predict_proba(X_valid)\n",
    "        xgb_test += model.predict_proba(X_test) / n_folds\n",
    "\n",
    "    log_score = log_loss(y, xgb_val)\n",
    "    print(f\"Xgb Log Loss Score: {log_score:.5f}\\n\")\n",
    "    return xgb_val, xgb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------XGB 0번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09165\tvalidation_1-mlogloss:1.09182\n",
      "[500]\tvalidation_0-mlogloss:0.61584\tvalidation_1-mlogloss:0.72825\n",
      "[1000]\tvalidation_0-mlogloss:0.49712\tvalidation_1-mlogloss:0.69773\n",
      "[1500]\tvalidation_0-mlogloss:0.42135\tvalidation_1-mlogloss:0.68753\n",
      "[1780]\tvalidation_0-mlogloss:0.39233\tvalidation_1-mlogloss:0.68672\n",
      "-----------XGB 1번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09159\tvalidation_1-mlogloss:1.09178\n",
      "[500]\tvalidation_0-mlogloss:0.61527\tvalidation_1-mlogloss:0.74141\n",
      "[1000]\tvalidation_0-mlogloss:0.49526\tvalidation_1-mlogloss:0.71835\n",
      "[1500]\tvalidation_0-mlogloss:0.41962\tvalidation_1-mlogloss:0.71391\n",
      "[1534]\tvalidation_0-mlogloss:0.41555\tvalidation_1-mlogloss:0.71397\n",
      "-----------XGB 2번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09160\tvalidation_1-mlogloss:1.09196\n",
      "[500]\tvalidation_0-mlogloss:0.61598\tvalidation_1-mlogloss:0.74790\n",
      "[1000]\tvalidation_0-mlogloss:0.49645\tvalidation_1-mlogloss:0.72139\n",
      "[1500]\tvalidation_0-mlogloss:0.42002\tvalidation_1-mlogloss:0.71572\n",
      "[1629]\tvalidation_0-mlogloss:0.40542\tvalidation_1-mlogloss:0.71616\n",
      "-----------XGB 3번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09163\tvalidation_1-mlogloss:1.09183\n",
      "[500]\tvalidation_0-mlogloss:0.61430\tvalidation_1-mlogloss:0.74173\n",
      "[1000]\tvalidation_0-mlogloss:0.49464\tvalidation_1-mlogloss:0.72014\n",
      "[1465]\tvalidation_0-mlogloss:0.42255\tvalidation_1-mlogloss:0.71713\n",
      "-----------XGB 4번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09161\tvalidation_1-mlogloss:1.09196\n",
      "[500]\tvalidation_0-mlogloss:0.61453\tvalidation_1-mlogloss:0.74650\n",
      "[1000]\tvalidation_0-mlogloss:0.49568\tvalidation_1-mlogloss:0.72014\n",
      "[1500]\tvalidation_0-mlogloss:0.41984\tvalidation_1-mlogloss:0.71178\n",
      "[1823]\tvalidation_0-mlogloss:0.38724\tvalidation_1-mlogloss:0.71155\n",
      "-----------XGB 5번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09158\tvalidation_1-mlogloss:1.09169\n",
      "[500]\tvalidation_0-mlogloss:0.61411\tvalidation_1-mlogloss:0.73806\n",
      "[1000]\tvalidation_0-mlogloss:0.49604\tvalidation_1-mlogloss:0.71266\n",
      "[1500]\tvalidation_0-mlogloss:0.42154\tvalidation_1-mlogloss:0.70527\n",
      "[1727]\tvalidation_0-mlogloss:0.39707\tvalidation_1-mlogloss:0.70466\n",
      "-----------XGB 6번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09168\tvalidation_1-mlogloss:1.09179\n",
      "[500]\tvalidation_0-mlogloss:0.61585\tvalidation_1-mlogloss:0.73766\n",
      "[1000]\tvalidation_0-mlogloss:0.49709\tvalidation_1-mlogloss:0.71184\n",
      "[1500]\tvalidation_0-mlogloss:0.42027\tvalidation_1-mlogloss:0.70541\n",
      "[1724]\tvalidation_0-mlogloss:0.39587\tvalidation_1-mlogloss:0.70500\n",
      "-----------XGB 7번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09163\tvalidation_1-mlogloss:1.09156\n",
      "[500]\tvalidation_0-mlogloss:0.61672\tvalidation_1-mlogloss:0.71756\n",
      "[1000]\tvalidation_0-mlogloss:0.49726\tvalidation_1-mlogloss:0.68957\n",
      "[1500]\tvalidation_0-mlogloss:0.42127\tvalidation_1-mlogloss:0.68256\n",
      "[1705]\tvalidation_0-mlogloss:0.39910\tvalidation_1-mlogloss:0.68220\n",
      "-----------XGB 8번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09163\tvalidation_1-mlogloss:1.09171\n",
      "[500]\tvalidation_0-mlogloss:0.61627\tvalidation_1-mlogloss:0.72741\n",
      "[1000]\tvalidation_0-mlogloss:0.49768\tvalidation_1-mlogloss:0.69930\n",
      "[1500]\tvalidation_0-mlogloss:0.42138\tvalidation_1-mlogloss:0.69130\n",
      "[1836]\tvalidation_0-mlogloss:0.38734\tvalidation_1-mlogloss:0.69104\n",
      "-----------XGB 9번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09160\tvalidation_1-mlogloss:1.09198\n",
      "[500]\tvalidation_0-mlogloss:0.61565\tvalidation_1-mlogloss:0.75015\n",
      "[1000]\tvalidation_0-mlogloss:0.49630\tvalidation_1-mlogloss:0.72624\n",
      "[1500]\tvalidation_0-mlogloss:0.42022\tvalidation_1-mlogloss:0.72088\n",
      "[1553]\tvalidation_0-mlogloss:0.41442\tvalidation_1-mlogloss:0.72112\n",
      "-----------XGB 10번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09158\tvalidation_1-mlogloss:1.09201\n",
      "[500]\tvalidation_0-mlogloss:0.61546\tvalidation_1-mlogloss:0.76176\n",
      "[1000]\tvalidation_0-mlogloss:0.49535\tvalidation_1-mlogloss:0.73800\n",
      "[1500]\tvalidation_0-mlogloss:0.41948\tvalidation_1-mlogloss:0.73420\n",
      "[1519]\tvalidation_0-mlogloss:0.41722\tvalidation_1-mlogloss:0.73405\n",
      "-----------XGB 11번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09160\tvalidation_1-mlogloss:1.09184\n",
      "[500]\tvalidation_0-mlogloss:0.61420\tvalidation_1-mlogloss:0.76352\n",
      "[1000]\tvalidation_0-mlogloss:0.49420\tvalidation_1-mlogloss:0.74879\n",
      "[1329]\tvalidation_0-mlogloss:0.44062\tvalidation_1-mlogloss:0.74746\n",
      "-----------XGB 12번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09168\tvalidation_1-mlogloss:1.09178\n",
      "[500]\tvalidation_0-mlogloss:0.61639\tvalidation_1-mlogloss:0.73611\n",
      "[1000]\tvalidation_0-mlogloss:0.49755\tvalidation_1-mlogloss:0.71250\n",
      "[1486]\tvalidation_0-mlogloss:0.42259\tvalidation_1-mlogloss:0.70961\n",
      "-----------XGB 13번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09163\tvalidation_1-mlogloss:1.09170\n",
      "[500]\tvalidation_0-mlogloss:0.61473\tvalidation_1-mlogloss:0.74789\n",
      "[1000]\tvalidation_0-mlogloss:0.49554\tvalidation_1-mlogloss:0.73176\n",
      "[1303]\tvalidation_0-mlogloss:0.44559\tvalidation_1-mlogloss:0.73013\n",
      "-----------XGB 14번-----------\n",
      "[0]\tvalidation_0-mlogloss:1.09167\tvalidation_1-mlogloss:1.09185\n",
      "[500]\tvalidation_0-mlogloss:0.61437\tvalidation_1-mlogloss:0.74457\n",
      "[1000]\tvalidation_0-mlogloss:0.49600\tvalidation_1-mlogloss:0.72328\n",
      "[1500]\tvalidation_0-mlogloss:0.42035\tvalidation_1-mlogloss:0.71808\n",
      "[1639]\tvalidation_0-mlogloss:0.40481\tvalidation_1-mlogloss:0.71814\n",
      "Xgb Log Loss Score: 0.71233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_val, xgb_test = train_xgb(n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(n_folds):\n",
    "    folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=4558)\n",
    "    splits = folds.split(X, y)\n",
    "    rf_val = np.zeros((X.shape[0], 3))\n",
    "    rf_test = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f\"-----------RandomForest {fold}번-----------\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = RandomForestClassifier(**param_rf)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        rf_val[valid_idx] = model.predict_proba(X_valid)\n",
    "        rf_test += model.predict_proba(X_test) / n_folds\n",
    "        print(f\"Log Loss Score: {log_loss(y_valid, rf_val[valid_idx]):.5f}\")\n",
    "\n",
    "    log_score = log_loss(y, rf_val)\n",
    "    print(f\"RandomForest Log Loss Score: {log_score:.5f}\\n\")\n",
    "    return rf_val, rf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------RandomForest 0번-----------\n",
      "Log Loss Score: 0.69864\n",
      "-----------RandomForest 1번-----------\n",
      "Log Loss Score: 0.72244\n",
      "-----------RandomForest 2번-----------\n",
      "Log Loss Score: 0.72294\n",
      "-----------RandomForest 3번-----------\n",
      "Log Loss Score: 0.73472\n",
      "-----------RandomForest 4번-----------\n",
      "Log Loss Score: 0.71388\n",
      "-----------RandomForest 5번-----------\n",
      "Log Loss Score: 0.70889\n",
      "-----------RandomForest 6번-----------\n",
      "Log Loss Score: 0.72111\n",
      "-----------RandomForest 7번-----------\n",
      "Log Loss Score: 0.69382\n",
      "-----------RandomForest 8번-----------\n",
      "Log Loss Score: 0.69702\n",
      "-----------RandomForest 9번-----------\n",
      "Log Loss Score: 0.72157\n",
      "-----------RandomForest 10번-----------\n",
      "Log Loss Score: 0.73967\n",
      "-----------RandomForest 11번-----------\n",
      "Log Loss Score: 0.74071\n",
      "-----------RandomForest 12번-----------\n",
      "Log Loss Score: 0.71317\n",
      "-----------RandomForest 13번-----------\n",
      "Log Loss Score: 0.72824\n",
      "-----------RandomForest 14번-----------\n",
      "Log Loss Score: 0.72194\n",
      "RandomForest Log Loss Score: 0.71858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_val, rf_test = train_rf(n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 결과 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pred\n",
      "[[0.07699502 0.16798797 0.755017   ... 0.21653738 0.1937674  0.58969522]\n",
      " [0.65685546 0.08425705 0.25888749 ... 0.52458428 0.12820767 0.34720805]\n",
      " [0.04616581 0.09571085 0.85812334 ... 0.05534404 0.41102911 0.53362685]\n",
      " ...\n",
      " [0.09876626 0.21892352 0.68231022 ... 0.08765252 0.24270516 0.66964232]\n",
      " [0.07571    0.1378242  0.7864658  ... 0.12391886 0.21652534 0.6595558 ]\n",
      " [0.09027888 0.16667268 0.74304844 ... 0.11172791 0.24088516 0.64738693]]\n",
      "(26457, 12)\n",
      "\n",
      "test_pred\n",
      "[[0.11244988 0.17371823 0.71383189 ... 0.05981103 0.17805626 0.7621327 ]\n",
      " [0.3371832  0.23365793 0.42915887 ... 0.2467788  0.22984613 0.52337507]\n",
      " [0.04327082 0.0747881  0.88194108 ... 0.0621314  0.08543021 0.85243839]\n",
      " ...\n",
      " [0.04724408 0.10725124 0.84550467 ... 0.05004236 0.11116913 0.83878851]\n",
      " [0.1454231  0.29471245 0.55986445 ... 0.13806908 0.27613325 0.58579766]\n",
      " [0.07445797 0.42042342 0.50511861 ... 0.16543603 0.26305406 0.57150991]]\n",
      "(10000, 12)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 모델에서의 예측 결과 모두 결합\n",
    "train_pred = np.concatenate([cat_val, lgbm_val, xgb_val, rf_val], axis=1)\n",
    "test_pred = np.concatenate([cat_test, lgbm_test, xgb_test, rf_test], axis=1)\n",
    "print(f'train_pred\\n{train_pred}\\n{train_pred.shape}\\n')\n",
    "print(f'test_pred\\n{test_pred}\\n{test_pred.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier로 최종 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Stacked LGBM 1번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.686182\tvalid_1's multi_logloss: 0.674587\n",
      "[200]\ttraining's multi_logloss: 0.665489\tvalid_1's multi_logloss: 0.653541\n",
      "[300]\ttraining's multi_logloss: 0.659295\tvalid_1's multi_logloss: 0.649171\n",
      "[400]\ttraining's multi_logloss: 0.656164\tvalid_1's multi_logloss: 0.647793\n",
      "[500]\ttraining's multi_logloss: 0.653884\tvalid_1's multi_logloss: 0.647349\n",
      "[600]\ttraining's multi_logloss: 0.652135\tvalid_1's multi_logloss: 0.647078\n",
      "[700]\ttraining's multi_logloss: 0.650591\tvalid_1's multi_logloss: 0.646977\n",
      "Early stopping, best iteration is:\n",
      "[687]\ttraining's multi_logloss: 0.650766\tvalid_1's multi_logloss: 0.646916\n",
      "-----------Stacked LGBM 2번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.684768\tvalid_1's multi_logloss: 0.689101\n",
      "[200]\ttraining's multi_logloss: 0.664037\tvalid_1's multi_logloss: 0.672385\n",
      "[300]\ttraining's multi_logloss: 0.657845\tvalid_1's multi_logloss: 0.669212\n",
      "[400]\ttraining's multi_logloss: 0.654716\tvalid_1's multi_logloss: 0.668838\n",
      "[500]\ttraining's multi_logloss: 0.652454\tvalid_1's multi_logloss: 0.668937\n",
      "Early stopping, best iteration is:\n",
      "[435]\ttraining's multi_logloss: 0.653873\tvalid_1's multi_logloss: 0.668755\n",
      "-----------Stacked LGBM 3번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.684808\tvalid_1's multi_logloss: 0.690588\n",
      "[200]\ttraining's multi_logloss: 0.664367\tvalid_1's multi_logloss: 0.67176\n",
      "[300]\ttraining's multi_logloss: 0.658339\tvalid_1's multi_logloss: 0.666859\n",
      "[400]\ttraining's multi_logloss: 0.655333\tvalid_1's multi_logloss: 0.664927\n",
      "[500]\ttraining's multi_logloss: 0.653245\tvalid_1's multi_logloss: 0.664003\n",
      "[600]\ttraining's multi_logloss: 0.651527\tvalid_1's multi_logloss: 0.663123\n",
      "[700]\ttraining's multi_logloss: 0.650056\tvalid_1's multi_logloss: 0.662566\n",
      "[800]\ttraining's multi_logloss: 0.648815\tvalid_1's multi_logloss: 0.662239\n",
      "[900]\ttraining's multi_logloss: 0.647774\tvalid_1's multi_logloss: 0.661961\n",
      "[1000]\ttraining's multi_logloss: 0.646803\tvalid_1's multi_logloss: 0.661846\n",
      "Early stopping, best iteration is:\n",
      "[974]\ttraining's multi_logloss: 0.647036\tvalid_1's multi_logloss: 0.661794\n",
      "-----------Stacked LGBM 4번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.683477\tvalid_1's multi_logloss: 0.702061\n",
      "[200]\ttraining's multi_logloss: 0.662581\tvalid_1's multi_logloss: 0.68828\n",
      "[300]\ttraining's multi_logloss: 0.656369\tvalid_1's multi_logloss: 0.68565\n",
      "[400]\ttraining's multi_logloss: 0.653179\tvalid_1's multi_logloss: 0.685241\n",
      "[500]\ttraining's multi_logloss: 0.651014\tvalid_1's multi_logloss: 0.685194\n",
      "Early stopping, best iteration is:\n",
      "[449]\ttraining's multi_logloss: 0.652025\tvalid_1's multi_logloss: 0.685072\n",
      "-----------Stacked LGBM 5번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.685615\tvalid_1's multi_logloss: 0.682853\n",
      "[200]\ttraining's multi_logloss: 0.665099\tvalid_1's multi_logloss: 0.660872\n",
      "[300]\ttraining's multi_logloss: 0.659076\tvalid_1's multi_logloss: 0.655067\n",
      "[400]\ttraining's multi_logloss: 0.655916\tvalid_1's multi_logloss: 0.653231\n",
      "[500]\ttraining's multi_logloss: 0.653804\tvalid_1's multi_logloss: 0.652502\n",
      "[600]\ttraining's multi_logloss: 0.652019\tvalid_1's multi_logloss: 0.651899\n",
      "[700]\ttraining's multi_logloss: 0.650622\tvalid_1's multi_logloss: 0.651641\n",
      "[800]\ttraining's multi_logloss: 0.649402\tvalid_1's multi_logloss: 0.651257\n",
      "[900]\ttraining's multi_logloss: 0.648313\tvalid_1's multi_logloss: 0.651242\n",
      "[1000]\ttraining's multi_logloss: 0.647333\tvalid_1's multi_logloss: 0.651101\n",
      "[1100]\ttraining's multi_logloss: 0.646438\tvalid_1's multi_logloss: 0.651106\n",
      "Early stopping, best iteration is:\n",
      "[1021]\ttraining's multi_logloss: 0.647161\tvalid_1's multi_logloss: 0.651034\n",
      "-----------Stacked LGBM 6번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.684894\tvalid_1's multi_logloss: 0.689134\n",
      "[200]\ttraining's multi_logloss: 0.663886\tvalid_1's multi_logloss: 0.670927\n",
      "[300]\ttraining's multi_logloss: 0.657638\tvalid_1's multi_logloss: 0.667071\n",
      "[400]\ttraining's multi_logloss: 0.654524\tvalid_1's multi_logloss: 0.666536\n",
      "[500]\ttraining's multi_logloss: 0.652404\tvalid_1's multi_logloss: 0.666367\n",
      "[600]\ttraining's multi_logloss: 0.650647\tvalid_1's multi_logloss: 0.666304\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's multi_logloss: 0.651531\tvalid_1's multi_logloss: 0.666273\n",
      "-----------Stacked LGBM 7번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.684802\tvalid_1's multi_logloss: 0.688033\n",
      "[200]\ttraining's multi_logloss: 0.664111\tvalid_1's multi_logloss: 0.66956\n",
      "[300]\ttraining's multi_logloss: 0.657953\tvalid_1's multi_logloss: 0.665927\n",
      "[400]\ttraining's multi_logloss: 0.654851\tvalid_1's multi_logloss: 0.665071\n",
      "[500]\ttraining's multi_logloss: 0.652629\tvalid_1's multi_logloss: 0.664887\n",
      "[600]\ttraining's multi_logloss: 0.650823\tvalid_1's multi_logloss: 0.66485\n",
      "Early stopping, best iteration is:\n",
      "[545]\ttraining's multi_logloss: 0.651734\tvalid_1's multi_logloss: 0.664774\n",
      "-----------Stacked LGBM 8번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.686482\tvalid_1's multi_logloss: 0.667944\n",
      "[200]\ttraining's multi_logloss: 0.665922\tvalid_1's multi_logloss: 0.646742\n",
      "[300]\ttraining's multi_logloss: 0.659794\tvalid_1's multi_logloss: 0.64251\n",
      "[400]\ttraining's multi_logloss: 0.656612\tvalid_1's multi_logloss: 0.64106\n",
      "[500]\ttraining's multi_logloss: 0.654443\tvalid_1's multi_logloss: 0.64072\n",
      "[600]\ttraining's multi_logloss: 0.652644\tvalid_1's multi_logloss: 0.640239\n",
      "[700]\ttraining's multi_logloss: 0.651104\tvalid_1's multi_logloss: 0.640043\n",
      "[800]\ttraining's multi_logloss: 0.649871\tvalid_1's multi_logloss: 0.640059\n",
      "Early stopping, best iteration is:\n",
      "[713]\ttraining's multi_logloss: 0.650941\tvalid_1's multi_logloss: 0.640017\n",
      "-----------Stacked LGBM 9번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.687012\tvalid_1's multi_logloss: 0.665099\n",
      "[200]\ttraining's multi_logloss: 0.66629\tvalid_1's multi_logloss: 0.641527\n",
      "[300]\ttraining's multi_logloss: 0.660169\tvalid_1's multi_logloss: 0.636657\n",
      "[400]\ttraining's multi_logloss: 0.657001\tvalid_1's multi_logloss: 0.634908\n",
      "[500]\ttraining's multi_logloss: 0.654662\tvalid_1's multi_logloss: 0.634628\n",
      "[600]\ttraining's multi_logloss: 0.653016\tvalid_1's multi_logloss: 0.634179\n",
      "[700]\ttraining's multi_logloss: 0.651567\tvalid_1's multi_logloss: 0.633967\n",
      "[800]\ttraining's multi_logloss: 0.650333\tvalid_1's multi_logloss: 0.634022\n",
      "Early stopping, best iteration is:\n",
      "[786]\ttraining's multi_logloss: 0.650486\tvalid_1's multi_logloss: 0.633958\n",
      "-----------Stacked LGBM 10번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.684687\tvalid_1's multi_logloss: 0.691186\n",
      "[200]\ttraining's multi_logloss: 0.66399\tvalid_1's multi_logloss: 0.673369\n",
      "[300]\ttraining's multi_logloss: 0.657835\tvalid_1's multi_logloss: 0.669563\n",
      "[400]\ttraining's multi_logloss: 0.654733\tvalid_1's multi_logloss: 0.668504\n",
      "[500]\ttraining's multi_logloss: 0.652517\tvalid_1's multi_logloss: 0.668095\n",
      "[600]\ttraining's multi_logloss: 0.650776\tvalid_1's multi_logloss: 0.667708\n",
      "[700]\ttraining's multi_logloss: 0.649347\tvalid_1's multi_logloss: 0.667674\n",
      "[800]\ttraining's multi_logloss: 0.648166\tvalid_1's multi_logloss: 0.667616\n",
      "[900]\ttraining's multi_logloss: 0.647146\tvalid_1's multi_logloss: 0.667752\n",
      "Early stopping, best iteration is:\n",
      "[824]\ttraining's multi_logloss: 0.647946\tvalid_1's multi_logloss: 0.667586\n",
      "-----------Stacked LGBM 11번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.683781\tvalid_1's multi_logloss: 0.705002\n",
      "[200]\ttraining's multi_logloss: 0.662959\tvalid_1's multi_logloss: 0.688446\n",
      "[300]\ttraining's multi_logloss: 0.656837\tvalid_1's multi_logloss: 0.684532\n",
      "[400]\ttraining's multi_logloss: 0.653722\tvalid_1's multi_logloss: 0.683025\n",
      "[500]\ttraining's multi_logloss: 0.651502\tvalid_1's multi_logloss: 0.682726\n",
      "[600]\ttraining's multi_logloss: 0.649725\tvalid_1's multi_logloss: 0.682687\n",
      "[700]\ttraining's multi_logloss: 0.648281\tvalid_1's multi_logloss: 0.68273\n",
      "Early stopping, best iteration is:\n",
      "[644]\ttraining's multi_logloss: 0.649069\tvalid_1's multi_logloss: 0.682628\n",
      "-----------Stacked LGBM 12번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.683716\tvalid_1's multi_logloss: 0.702494\n",
      "[200]\ttraining's multi_logloss: 0.662935\tvalid_1's multi_logloss: 0.686577\n",
      "[300]\ttraining's multi_logloss: 0.656761\tvalid_1's multi_logloss: 0.683337\n",
      "[400]\ttraining's multi_logloss: 0.653678\tvalid_1's multi_logloss: 0.682083\n",
      "[500]\ttraining's multi_logloss: 0.651572\tvalid_1's multi_logloss: 0.681507\n",
      "[600]\ttraining's multi_logloss: 0.64983\tvalid_1's multi_logloss: 0.681219\n",
      "[700]\ttraining's multi_logloss: 0.648271\tvalid_1's multi_logloss: 0.680941\n",
      "[800]\ttraining's multi_logloss: 0.6471\tvalid_1's multi_logloss: 0.680649\n",
      "[900]\ttraining's multi_logloss: 0.646072\tvalid_1's multi_logloss: 0.680429\n",
      "[1000]\ttraining's multi_logloss: 0.645069\tvalid_1's multi_logloss: 0.680322\n",
      "[1100]\ttraining's multi_logloss: 0.644098\tvalid_1's multi_logloss: 0.680269\n",
      "[1200]\ttraining's multi_logloss: 0.643316\tvalid_1's multi_logloss: 0.680234\n",
      "[1300]\ttraining's multi_logloss: 0.642564\tvalid_1's multi_logloss: 0.680271\n",
      "Early stopping, best iteration is:\n",
      "[1243]\ttraining's multi_logloss: 0.643025\tvalid_1's multi_logloss: 0.680163\n",
      "-----------Stacked LGBM 13번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.684752\tvalid_1's multi_logloss: 0.689814\n",
      "[200]\ttraining's multi_logloss: 0.66387\tvalid_1's multi_logloss: 0.673318\n",
      "[300]\ttraining's multi_logloss: 0.657613\tvalid_1's multi_logloss: 0.67033\n",
      "[400]\ttraining's multi_logloss: 0.654506\tvalid_1's multi_logloss: 0.669418\n",
      "[500]\ttraining's multi_logloss: 0.65236\tvalid_1's multi_logloss: 0.669127\n",
      "[600]\ttraining's multi_logloss: 0.650619\tvalid_1's multi_logloss: 0.669135\n",
      "Early stopping, best iteration is:\n",
      "[517]\ttraining's multi_logloss: 0.652023\tvalid_1's multi_logloss: 0.669057\n",
      "-----------Stacked LGBM 14번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.684095\tvalid_1's multi_logloss: 0.697473\n",
      "[200]\ttraining's multi_logloss: 0.663249\tvalid_1's multi_logloss: 0.680819\n",
      "[300]\ttraining's multi_logloss: 0.657278\tvalid_1's multi_logloss: 0.676522\n",
      "[400]\ttraining's multi_logloss: 0.65413\tvalid_1's multi_logloss: 0.674546\n",
      "[500]\ttraining's multi_logloss: 0.652067\tvalid_1's multi_logloss: 0.673666\n",
      "[600]\ttraining's multi_logloss: 0.650324\tvalid_1's multi_logloss: 0.672792\n",
      "[700]\ttraining's multi_logloss: 0.648925\tvalid_1's multi_logloss: 0.672384\n",
      "[800]\ttraining's multi_logloss: 0.647713\tvalid_1's multi_logloss: 0.67209\n",
      "[900]\ttraining's multi_logloss: 0.646648\tvalid_1's multi_logloss: 0.671976\n",
      "Early stopping, best iteration is:\n",
      "[882]\ttraining's multi_logloss: 0.646802\tvalid_1's multi_logloss: 0.67196\n",
      "-----------Stacked LGBM 15번-----------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8957366717057349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8957366717057349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=617, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=617\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.684208\tvalid_1's multi_logloss: 0.695797\n",
      "[200]\ttraining's multi_logloss: 0.663452\tvalid_1's multi_logloss: 0.679832\n",
      "[300]\ttraining's multi_logloss: 0.657359\tvalid_1's multi_logloss: 0.677394\n",
      "[400]\ttraining's multi_logloss: 0.654128\tvalid_1's multi_logloss: 0.676757\n",
      "[500]\ttraining's multi_logloss: 0.652037\tvalid_1's multi_logloss: 0.676759\n",
      "Early stopping, best iteration is:\n",
      "[445]\ttraining's multi_logloss: 0.6531\tvalid_1's multi_logloss: 0.676583\n",
      "0.6644369858985778\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=4558)\n",
    "stack_val = np.zeros((train_pred.shape[0], 3))\n",
    "stack_test = np.zeros((test_pred.shape[0], 3))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(folds.split(train_pred, y), 1):\n",
    "    print(f\"-----------Stacked LGBM {fold}번-----------\")\n",
    "    X_train, X_valid = train_pred[train_idx], train_pred[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    model = LGBMClassifier(**param_lgbm_last)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=100)])\n",
    "\n",
    "    stack_val[valid_idx, :] = model.predict_proba(train_pred[valid_idx])\n",
    "    stack_test += model.predict_proba(test_pred) / n_folds\n",
    "\n",
    "loss = log_loss(y, stack_val)\n",
    "print(f'{loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k1a2/anaconda3/envs/ml/lib/python3.8/site-packages/pandas/core/indexing.py:719: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  indexer = self._get_setitem_indexer(key)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.098574</td>\n",
       "      <td>0.206903</td>\n",
       "      <td>0.694523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.333605</td>\n",
       "      <td>0.247072</td>\n",
       "      <td>0.419324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.057823</td>\n",
       "      <td>0.904292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.048531</td>\n",
       "      <td>0.067786</td>\n",
       "      <td>0.883683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>0.205349</td>\n",
       "      <td>0.720949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>0.055489</td>\n",
       "      <td>0.207363</td>\n",
       "      <td>0.737149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>0.222826</td>\n",
       "      <td>0.296583</td>\n",
       "      <td>0.480591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>0.055221</td>\n",
       "      <td>0.089584</td>\n",
       "      <td>0.855195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>0.105940</td>\n",
       "      <td>0.300948</td>\n",
       "      <td>0.593113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>0.065182</td>\n",
       "      <td>0.425401</td>\n",
       "      <td>0.509417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         0         1         2\n",
       "0     26457  0.098574  0.206903  0.694523\n",
       "1     26458  0.333605  0.247072  0.419324\n",
       "2     26459  0.037885  0.057823  0.904292\n",
       "3     26460  0.048531  0.067786  0.883683\n",
       "4     26461  0.073703  0.205349  0.720949\n",
       "...     ...       ...       ...       ...\n",
       "9995  36452  0.055489  0.207363  0.737149\n",
       "9996  36453  0.222826  0.296583  0.480591\n",
       "9997  36454  0.055221  0.089584  0.855195\n",
       "9998  36455  0.105940  0.300948  0.593113\n",
       "9999  36456  0.065182  0.425401  0.509417\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.loc[:, 1:] = stack_test\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'./data/submission/stacking_{n_folds}_{loss}_xgboost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPyHZDPdWMGPGrzkN2exHmy",
   "collapsed_sections": [],
   "mount_file_id": "12lQ5oybXkI9kDNOOoWT1EUwtzrLfQPJ1",
   "name": "데이콘_신용카드_예측제출.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
